<!DOCTYPE html><html lang="en"><head><meta name="generator" content="Hexo 3.9.0"><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><title>PyTorch | 404</title><meta name="description" content="intro of PyTorch"><meta name="keywords" content="PyTorch"><meta name="author" content="shixuan liu"><meta name="copyright" content="shixuan liu"><meta name="format-detection" content="telephone=no"><link rel="shortcut icon" href="/favicon.ico"><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.8.1/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><meta http-equiv="x-dns-prefetch-control" content="on"><link rel="canonical" href="http://tedlsx.github.io/2020/01/07/pytorch/"><meta name="twitter:card" content="summary_large_image"><meta name="twitter:title" content="PyTorch"><meta name="twitter:description" content="intro of PyTorch"><meta name="twitter:image" content="https://live.staticflickr.com/65535/49241182478_46e7d63095_t.jpg"><meta property="og:type" content="article"><meta property="og:title" content="PyTorch"><meta property="og:url" content="http://tedlsx.github.io/2020/01/07/pytorch/"><meta property="og:site_name" content="404"><meta property="og:description" content="intro of PyTorch"><meta property="og:image" content="https://live.staticflickr.com/65535/49241182478_46e7d63095_t.jpg"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="next" title="Long Short Term Memory" href="http://tedlsx.github.io/2019/10/18/lstm/"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.css"><script src="https://cdn.jsdelivr.net/npm/gitalk@latest/dist/gitalk.min.js"></script><script src="https://cdn.jsdelivr.net/npm/blueimp-md5@2.10.0/js/md5.min.js"></script><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"We didn't find any results for the search: ${query}"}},
  translate: {"defaultEncoding":1,"translateDelay":0,"cookieDomain":"https://xxx/","msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"简"},
  highlight_copy: 'true',
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  bookmark: {
    title: 'Bookmark',
    message_prev: 'Press',
    message_next: 'to bookmark this page'
  },
  runtime_unit: 'days'

  
}</script></head><body><canvas class="fireworks"></canvas><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div class="auto_open" id="sidebar"><div class="sidebar-toc"><div class="sidebar-toc__title">Catalog</div><div class="sidebar-toc__progress"><span class="progress-notice">You've read</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar"></div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#what-is-pytorch"><span class="toc-number">1.</span> <span class="toc-text"> What is PyTorch</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#diff-between-tensorflow-and-pytorch"><span class="toc-number">2.</span> <span class="toc-text"> Diff between Tensorflow and PyTorch</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#tensors"><span class="toc-number">3.</span> <span class="toc-text"> Tensors</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#gradients"><span class="toc-number">4.</span> <span class="toc-text"> Gradients</span></a></li></ol></div></div></div><div id="content-outer"><div id="top-container" style="background-image: url(https://live.staticflickr.com/65535/48621182418_494606b3cf_o.jpg)"><div id="page-header"><span class="pull-left"> <a class="blog_title" id="site-name" href="/">404</a></span><div class="open toggle-menu pull-right"><div class="menu-icon-first"></div><div class="menu-icon-second"></div><div class="menu-icon-third"></div></div><span class="pull-right menus"><div class="mobile_author_icon"><img class="lozad" src="https://live.staticflickr.com/65535/49241182478_46e7d63095_t.jpg" onerror="onerror=null;src='/img/friend_404.gif'"><div class="mobile_author-info__description"></div></div><hr><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a><a class="site-page" href="/gallery/"><i class="fa-fw fas fa-images"></i><span> Gallery</span></a><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a><script>document.body.addEventListener('touchstart', function(){ });</script></div></span><span class="pull-right"><a class="site-page social-icon search"><i class="fa fa-search fa-fw"></i><span> Search</span></a></span></div><div id="post-info"><div id="post-title"><div class="posttitle">PyTorch</div></div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> Created 2020-01-07<span class="post-meta__separator">|</span><i class="fa fa-history" aria-hidden="true"></i> Updated 2020-01-07</time><div class="post-meta-wordcount"><span>Word count: </span><span class="word-count">869</span><span class="post-meta__separator">|</span><span>Reading time: 4 min</span><span class="post-meta__separator">|</span><span>Post View: </span><span id="busuanzi_value_page_pv"></span></div></div></div></div><div class="layout layout_post" id="content-inner">   <article id="post"><div class="article-container" id="post-content"><h2 id="what-is-pytorch"><a class="markdownIt-Anchor" href="#what-is-pytorch"></a> What is PyTorch</h2>
<p>In official website: <a href="https://pytorch.org/tutorials/" target="_blank" rel="noopener">https://pytorch.org/tutorials/</a> . It states that</p>
<ul>
<li>A replacement for NumPy to use the power of GPUs</li>
<li>A deep learning research platform that provides maximum flexibility and speed</li>
</ul>
<h2 id="diff-between-tensorflow-and-pytorch"><a class="markdownIt-Anchor" href="#diff-between-tensorflow-and-pytorch"></a> Diff between Tensorflow and PyTorch</h2>
<p>The most important difference between the two is the way these frameworks define the computational graphs. While Tensorflow creates a static graph, PyTorch believes in a dynamic graph. So what does this mean? In Tensorflow, you first have to define the entire computation graph of the model and then run your ML model. But in PyTorch, you can define/manipulate your graph on-the-go. This is particularly helpful while using variable length inputs in RNNs.</p>
<h2 id="tensors"><a class="markdownIt-Anchor" href="#tensors"></a> Tensors</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">x = torch.empty(<span class="number">5</span>,<span class="number">3</span>)</span><br><span class="line">x</span><br><span class="line"><span class="comment"># out</span></span><br><span class="line">tensor([[<span class="number">1.1210e-44</span>, <span class="number">0.0000e+00</span>, <span class="number">0.0000e+00</span>],</span><br><span class="line">        [<span class="number">0.0000e+00</span>, <span class="number">0.0000e+00</span>, <span class="number">0.0000e+00</span>],</span><br><span class="line">        [<span class="number">0.0000e+00</span>, <span class="number">0.0000e+00</span>, <span class="number">0.0000e+00</span>],</span><br><span class="line">        [<span class="number">0.0000e+00</span>, <span class="number">0.0000e+00</span>, <span class="number">0.0000e+00</span>],</span><br><span class="line">        [<span class="number">0.0000e+00</span>, <span class="number">0.0000e+00</span>, <span class="number">0.0000e+00</span>]])</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">x = torch.rand(<span class="number">5</span>, <span class="number">3</span>)</span><br><span class="line">x</span><br><span class="line"><span class="comment"># out</span></span><br><span class="line">tensor([[<span class="number">0.9122</span>, <span class="number">0.0691</span>, <span class="number">0.9595</span>],</span><br><span class="line">        [<span class="number">0.2535</span>, <span class="number">0.0617</span>, <span class="number">0.5030</span>],</span><br><span class="line">        [<span class="number">0.3705</span>, <span class="number">0.4274</span>, <span class="number">0.8880</span>],</span><br><span class="line">        [<span class="number">0.0304</span>, <span class="number">0.0172</span>, <span class="number">0.9135</span>],</span><br><span class="line">        [<span class="number">0.9683</span>, <span class="number">0.9874</span>, <span class="number">0.5131</span>]])</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">x = torch.zeros(<span class="number">5</span>, <span class="number">3</span>, dtype=torch.long)</span><br><span class="line">x</span><br><span class="line"><span class="comment"># out:</span></span><br><span class="line">tensor([[<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">        [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">        [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">        [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">        [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]])</span><br></pre></td></tr></table></figure>
<p>Reuse the input tensor</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">x = x.new_ones(<span class="number">5</span>, <span class="number">3</span>, dtype=torch.double)</span><br><span class="line">x</span><br><span class="line"><span class="comment"># out</span></span><br><span class="line">tensor([[<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>],</span><br><span class="line">        [<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>],</span><br><span class="line">        [<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>],</span><br><span class="line">        [<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>],</span><br><span class="line">        [<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>]], dtype=torch.float64)</span><br></pre></td></tr></table></figure>
<p>Override dtype</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">x = torch.randn_like(x, dtype=torch.float)</span><br><span class="line">x</span><br><span class="line"><span class="comment"># Out:</span></span><br><span class="line">tensor([[<span class="number">-0.6438</span>, <span class="number">-1.6627</span>, <span class="number">-1.0903</span>],</span><br><span class="line">        [ <span class="number">0.3002</span>,  <span class="number">0.4009</span>, <span class="number">-0.7618</span>],</span><br><span class="line">        [ <span class="number">0.1420</span>,  <span class="number">0.9419</span>,  <span class="number">0.1807</span>],</span><br><span class="line">        [<span class="number">-1.2571</span>,  <span class="number">0.0923</span>,  <span class="number">0.3649</span>],</span><br><span class="line">        [<span class="number">-0.2423</span>,  <span class="number">0.1674</span>,  <span class="number">0.6538</span>]])</span><br></pre></td></tr></table></figure>
<p>AUTOGRAD：自动分化<br>
PyTorch中所有神经网络的核心是autograd软件包。让我们先简要地介绍一下，然后再训练第一个神经网络。</p>
<p>autograd软件包为Tensor上的所有操作提供自动区分。这是一个按运行定义的框架，这意味着您的backprop是由代码的运行方式定义的，并且每次迭代都可以不同。</p>
<p>让我们通过一些示例以更简单的方式看待这一点。</p>
<p>张量<br>
<code>torch.Tensor</code>是程序包的中心类。如果将其属性<code>.requires_grad</code>设置为<code>True</code>，它将开始跟踪对其的所有操作。完成计算后，您可以调用<code>.backward()</code>并自动计算所有梯度。该张量的梯度将累积到<code>.grad</code>属性中。</p>
<p>要停止tensor(张量)跟踪历史记录，可以调用<code>.detach()</code>将其与计算历史记录分离，并防止跟踪将来的计算。</p>
<p>为了防止跟踪历史记录（和使用内存），您还可以使用<code>torch.no_grad()</code>：包装代码块。这在评估模型时特别有用，因为模型可能具有可训练的参数并使 <code>require_grad = True</code>，但我们不需要梯度。</p>
<p>还有另外一类对autograd非常重要，它是一个 <code>Function</code>。</p>
<p><code>Tensor</code>和<code>Function</code>相互连接并建立一个无环图，该图对完整的计算历史进行编码。每个tensor都有一个<code>.grad_fn</code>属性，该属性引用创建了张量的函数（用户创建的张量除外-它们的<code>grad_fn is None</code>）。</p>
<p>如果要计算导数，可以在Tensor上调用<code>.backward()</code>。如果Tensor是scalar标量（即，它包含一个元素数据），则无需为<code>Backward()</code>指定任何参数，但是，如果Tensor具有更多元素，则需要指定gradient梯度参数，该参数应匹配张量的shape。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">x = torch.ones(<span class="number">2</span>, <span class="number">2</span>, requires_grad=<span class="literal">True</span>)</span><br><span class="line">x</span><br><span class="line"><span class="comment"># out</span></span><br><span class="line">tensor([[<span class="number">1.</span>, <span class="number">1.</span>],</span><br><span class="line">        [<span class="number">1.</span>, <span class="number">1.</span>]], requires_grad=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># use tensor opperation</span></span><br><span class="line">y = x + <span class="number">2</span></span><br><span class="line">y</span><br><span class="line"><span class="comment"># out</span></span><br><span class="line">tensor([[<span class="number">3.</span>, <span class="number">3.</span>],</span><br><span class="line">        [<span class="number">3.</span>, <span class="number">3.</span>]], grad_fn=&lt;AddBackward0&gt;)</span><br><span class="line"></span><br><span class="line">y.grad_fn</span><br><span class="line"><span class="comment"># out</span></span><br><span class="line">&lt;AddBackward0 at <span class="number">0x7fac10f9d390</span>&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment"># more operation</span></span><br><span class="line">z = y * y * <span class="number">3</span></span><br><span class="line">out = z.mean()</span><br><span class="line">out</span><br><span class="line"></span><br><span class="line"><span class="comment"># out</span></span><br><span class="line">tensor(<span class="number">27.</span>, grad_fn=&lt;MeanBackward0&gt;)</span><br><span class="line"></span><br><span class="line"><span class="comment"># requires_grad has default False</span></span><br><span class="line">a = torch .randn(<span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">a = ((a * <span class="number">3</span>) / (a<span class="number">-1</span>))</span><br><span class="line">print(a.requires_grad)</span><br><span class="line"></span><br><span class="line">a.requires_grad_(<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">print(a.requires_grad)</span><br><span class="line"></span><br><span class="line">b = (a * a).sum()</span><br><span class="line">print(b.grad_fn)</span><br><span class="line"></span><br><span class="line"><span class="comment"># out </span></span><br><span class="line"><span class="literal">False</span></span><br><span class="line"><span class="literal">True</span></span><br><span class="line">&lt;SumBackward0 object at <span class="number">0x7fac11114940</span>&gt;</span><br></pre></td></tr></table></figure>
<h2 id="gradients"><a class="markdownIt-Anchor" href="#gradients"></a> Gradients</h2>
<p>Now backprop, since <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>o</mi><mi>u</mi><mi>t</mi></mrow><annotation encoding="application/x-tex">out</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.61508em;vertical-align:0em;"></span><span class="mord mathdefault">o</span><span class="mord mathdefault">u</span><span class="mord mathdefault">t</span></span></span></span> contains a single scalar then <code>out.backward()</code> is equivalent to <code>out.backward(torch.tensor(1,))</code></p>
<p>​</p>
</div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="mailto:undefined">shixuan liu</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="http://tedlsx.github.io/2020/01/07/pytorch/">http://tedlsx.github.io/2020/01/07/pytorch/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/PyTorch/">PyTorch    </a></div><div class="post_share"><div class="social-share" data-image="https://live.staticflickr.com/65535/49241182478_46e7d63095_t.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js@1.0.16/dist/css/share.min.css"><script src="https://cdn.jsdelivr.net/npm/social-share.js@1.0.16/dist/js/social-share.min.js"></script></div></div><div class="post-reward"><a class="reward-buttom"><i class="fa fa-qrcode"></i> Donate<div class="reward-main"><ul class="reward-all"><li class="reward-item"><img class="lozad post-qr-code__img" src="/img/wechat.jpeg"><div class="post-qr-code__desc">Wechat</div></li><li class="reward-item"><img class="lozad post-qr-code__img" src="/img/alipay.jpeg"><div class="post-qr-code__desc">Alipay</div></li></ul></div></a></div><nav class="pagination_post" id="pagination"><div class="next-post pull-full"><a href="/2019/10/18/lstm/"><img class="next_cover lozad" data-src="https://cdn.jsdelivr.net/gh/jerryc127/CDN@latest/cover/default_bg.png" onerror="onerror=null;src='/img/404.jpg'"><div class="label">Next Post</div><div class="next_info"><span>Long Short Term Memory</span></div></a></div></nav><hr><div id="post-comment"><div class="comment_headling"><i class="fa fa-comments fa-fw" aria-hidden="true"></i><span> Comment</span></div><div id="gitalk-container"></div><script>var gitalk = new Gitalk({
  clientID: '',
  clientSecret: '',
  repo: 'gitalk',
  owner: 'tedlsx',
  admin: 'tedlsx',
  id: md5(decodeURI(location.pathname)),
  language: ''
})
gitalk.render('gitalk-container')</script></div></div></div><footer><div class="layout" id="footer"><div class="copyright">&copy;2019 - 2020 By shixuan liu</div><div class="framework-info"><span>Driven </span><a href="http://hexo.io"><span>Hexo</span></a><span class="footer-separator">|</span><span>Theme </span><a href="https://github.com/jerryc127/hexo-theme-butterfly"><span>Butterfly</span></a></div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><section class="rightside" id="rightside"><i class="fa fa-book" id="readmode" title="Read Mode"> </i><i class="fa fa-plus" id="font_plus" title="Increase font size"></i><i class="fa fa-minus" id="font_minus" title="Decrease font size"></i><a class="translate_chn_to_cht" id="translateLink" href="javascript:translatePage();" title="Traditional Chinese and Simplified Chinese Conversion">简</a><i class="fa fa-moon-o nightshift" id="nightshift" title="Dark Mode"></i></section><div id="post_bottom"><div id="post_bottom_items"><a id="to_comment" href="#post-comment"><i class="scroll_to_comment fa fa-comments"></i></a><i class="fa fa-list" id="mobile_toc"></i><div id="toc_mobile"><div class="toc_mobile_headline">Catalog</div><ol class="toc_mobile_items"><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#what-is-pytorch"><span class="toc_mobile_items-number">1.</span> <span class="toc_mobile_items-text"> What is PyTorch</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#diff-between-tensorflow-and-pytorch"><span class="toc_mobile_items-number">2.</span> <span class="toc_mobile_items-text"> Diff between Tensorflow and PyTorch</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#tensors"><span class="toc_mobile_items-number">3.</span> <span class="toc_mobile_items-text"> Tensors</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#gradients"><span class="toc_mobile_items-number">4.</span> <span class="toc_mobile_items-text"> Gradients</span></a></li></ol></div></div></div><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/js-cookie@2/src/js.cookie.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.css"><script>$(function () {
  $('span.katex-display').wrap('<div class="katex-wrap"></div>')
})</script><script async src="/js/search/local-search.js"></script><script src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script src="/js/third-party/fireworks.js"></script><script src="/js/nightshift.js"></script><script id="ribbon" src="/js/third-party/canvas-ribbon.js" size="150" alpha="0.6" zindex="-1" data-click="false"></script><script id="ribbon" src="https://cdn.jsdelivr.net/gh/jerryc127/CDN@latest/js/piao.js"></script><script src="/js/activate-power-mode.js"></script><script>POWERMODE.colorful = true; // make power mode colorful
POWERMODE.shake = true; // turn off shake
document.body.addEventListener('input', POWERMODE);
</script><script src="/js/tw_cn.js"></script><script>translateInitilization()

</script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page@1.2.2/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/lozad/dist/lozad.min.js"></script><script>const observer = lozad(); // lazy loads elements with default selector as '.lozad'
observer.observe();</script><div class="search-dialog" id="local-search"><div class="search-dialog__title" id="local-search-title">Local search</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="Search for Posts"></div></div></div><hr><div id="local-search-results"><div id="local-hits"></div><div id="local-stats"><div class="local-search-stats__hr" id="hr"><span>Powered by</span> <a href="https://github.com/wzpan/hexo-generator-search" style="color:#49B1F5;">hexo-generator-search</a></div></div></div><span class="search-close-button"><i class="fa fa-times"></i></span></div><div class="search-mask"></div><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","model":{"jsonPath":"/live2dw/assets/shizuku.model.json"},"display":{"position":"right","width":150,"height":300,"hOffset":40,"vOffset":-10},"mobile":{"show":true},"log":false,"tagMode":false});</script></body></html>