<!DOCTYPE html><html lang="en"><head><meta name="generator" content="Hexo 3.9.0"><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><title>Spark for Machine Learning and AI | hoanjinan_otoko</title><meta name="description" content="This post is going to describe how to use the Apache Spark Platform for Machine Learning.  It will start by reviewing the basics of the dataframe data structure.  Then, it will cover the pre-processing to both numeric and text data so that is ready to use with Spark's MLlib machine learning library.  The post will also describe multiple algorithms for clustering, classification and regression.  In the end, it will briefly describe a recommendation system."><meta name="keywords" content="Big Data,Data Science,Data Processing,Machine Learning,AI,Model,Query"><meta name="author" content="Zilan Huang"><meta name="copyright" content="Zilan Huang"><meta name="format-detection" content="telephone=no"><link rel="shortcut icon" href="/img/favicon.png"><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.8.1/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><meta http-equiv="x-dns-prefetch-control" content="on"><link rel="canonical" href="http://tedlsx.github.io/2019/08/20/Spark-for-Machine-Learning-AI/"><meta name="twitter:card" content="summary_large_image"><meta name="twitter:title" content="Spark for Machine Learning and AI"><meta name="twitter:description" content="This post is going to describe how to use the Apache Spark Platform for Machine Learning.  It will start by reviewing the basics of the dataframe data structure.  Then, it will cover the pre-processing to both numeric and text data so that is ready to use with Spark's MLlib machine learning library.  The post will also describe multiple algorithms for clustering, classification and regression.  In the end, it will briefly describe a recommendation system."><meta name="twitter:image" content="http://tedlsx.github.io/img/spark.jpeg"><meta property="og:type" content="article"><meta property="og:title" content="Spark for Machine Learning and AI"><meta property="og:url" content="http://tedlsx.github.io/2019/08/20/Spark-for-Machine-Learning-AI/"><meta property="og:site_name" content="hoanjinan_otoko"><meta property="og:description" content="This post is going to describe how to use the Apache Spark Platform for Machine Learning.  It will start by reviewing the basics of the dataframe data structure.  Then, it will cover the pre-processing to both numeric and text data so that is ready to use with Spark's MLlib machine learning library.  The post will also describe multiple algorithms for clustering, classification and regression.  In the end, it will briefly describe a recommendation system."><meta property="og:image" content="http://tedlsx.github.io/img/spark.jpeg"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="next" title="Hadoop Environment Setup" href="http://tedlsx.github.io/2019/08/19/Hadoop-Environment-Setup/"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"We didn't find any results for the search: ${query}"}},
  translate: {"defaultEncoding":1,"translateDelay":0,"cookieDomain":"https://xxx/","msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"简"},
  highlight_copy: 'true',
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  bookmark: {
    title: 'Bookmark',
    message_prev: 'Press',
    message_next: 'to bookmark this page'
  },
  runtime_unit: 'days'

  
}</script></head><body><canvas class="fireworks"></canvas><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div class="auto_open" id="sidebar"><div class="sidebar-toc"><div class="sidebar-toc__title">Catalog</div><div class="sidebar-toc__progress"><span class="progress-notice">You've read</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar"></div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Introduction-to-The-Post"><span class="toc-number">1.</span> <span class="toc-text">Introduction to The Post</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Introduction-to-Spark"><span class="toc-number">2.</span> <span class="toc-text">Introduction to Spark</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Steps-in-Machine-Learning-Process"><span class="toc-number">3.</span> <span class="toc-text">Steps in Machine Learning Process</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Creating-Spark-Session-and-Basic-Dataframe-Processing"><span class="toc-number">4.</span> <span class="toc-text">Creating Spark Session and Basic Dataframe Processing</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Create-Spark-Session"><span class="toc-number">4.1.</span> <span class="toc-text">Create Spark Session</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Basic-Dataframe-Processing"><span class="toc-number">4.2.</span> <span class="toc-text">Basic Dataframe Processing</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Components-of-Spark-MLlib"><span class="toc-number">5.</span> <span class="toc-text">Components of Spark MLlib</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Introduction-to-Preprocessing"><span class="toc-number">6.</span> <span class="toc-text">Introduction to Preprocessing</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Numeric"><span class="toc-number">6.1.</span> <span class="toc-text">Numeric</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Normalisation-MinMaxScaler"><span class="toc-number">6.1.1.</span> <span class="toc-text">Normalisation (MinMaxScaler)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Standardisation-StandardScaler"><span class="toc-number">6.1.2.</span> <span class="toc-text">Standardisation (StandardScaler)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Partition-Bucketiser"><span class="toc-number">6.1.3.</span> <span class="toc-text">Partition (Bucketiser)</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Text"><span class="toc-number">6.2.</span> <span class="toc-text">Text</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Tokenisation-Tokeniser"><span class="toc-number">6.2.1.</span> <span class="toc-text">Tokenisation (Tokeniser)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Term-Frequency-Inverse-Document-Frequency-TF-IDF-Hashing-TF"><span class="toc-number">6.2.2.</span> <span class="toc-text">Term Frequency Inverse Document Frequency (TF-IDF) - (Hashing TF)</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Introduction-to-Clustering"><span class="toc-number">7.</span> <span class="toc-text">Introduction to Clustering</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#K-means-Clustering"><span class="toc-number">7.1.</span> <span class="toc-text">K-means Clustering</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Hierarchical-Clustering"><span class="toc-number">7.2.</span> <span class="toc-text">Hierarchical Clustering</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Introduction-to-Classification"><span class="toc-number">8.</span> <span class="toc-text">Introduction to Classification</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Preprocessing-The-Iris-Dataset"><span class="toc-number">8.1.</span> <span class="toc-text">Preprocessing The Iris Dataset</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Naive-Bayes-Classification"><span class="toc-number">8.2.</span> <span class="toc-text">Naive Bayes Classification</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Multilayer-Perceptron-Classification"><span class="toc-number">8.3.</span> <span class="toc-text">Multilayer Perceptron Classification</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Decision-Trees-Classification"><span class="toc-number">8.4.</span> <span class="toc-text">Decision Trees Classification</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Introduction-to-Regresssion"><span class="toc-number">9.</span> <span class="toc-text">Introduction to Regresssion</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Pre-processing-The-Dataset"><span class="toc-number">9.1.</span> <span class="toc-text">Pre-processing The Dataset</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Linear-Regression"><span class="toc-number">9.2.</span> <span class="toc-text">Linear Regression</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Decision-Tree-Regression"><span class="toc-number">9.3.</span> <span class="toc-text">Decision Tree Regression</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Gradient-boosted-Tree-Regression"><span class="toc-number">9.4.</span> <span class="toc-text">Gradient-boosted Tree Regression</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Understand-Recommendation-Systems"><span class="toc-number">10.</span> <span class="toc-text">Understand Recommendation Systems</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Collaborative-Filtering"><span class="toc-number">10.1.</span> <span class="toc-text">Collaborative Filtering</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Tips-for-Using-Spark-MLlib"><span class="toc-number">11.</span> <span class="toc-text">Tips for Using Spark MLlib</span></a></li></ol></div></div></div><div id="content-outer"><div id="top-container" style="background-image: url(/img/data_centre.jpg)"><div id="page-header"><span class="pull-left"> <a class="blog_title" id="site-name" href="/">hoanjinan_otoko</a></span><div class="open toggle-menu pull-right"><div class="menu-icon-first"></div><div class="menu-icon-second"></div><div class="menu-icon-third"></div></div><span class="pull-right menus"><div class="mobile_author_icon"><img class="lozad" src="https://live.staticflickr.com/65535/48621182898_91a9c4cc04_o.jpg" onerror="onerror=null;src='/img/friend_404.gif'"><div class="mobile_author-info__description"></div></div><hr><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a><a class="site-page" href="/gallery/"><i class="fa-fw fas fa-images"></i><span> Gallery</span></a><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a><script>document.body.addEventListener('touchstart', function(){ });</script></div></span><span class="pull-right"><a class="site-page social-icon search"><i class="fa fa-search fa-fw"></i><span> Search</span></a></span></div><div id="post-info"><div id="post-title"><div class="posttitle">Spark for Machine Learning and AI</div></div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> Created 2019-08-20<span class="post-meta__separator">|</span><i class="fa fa-history" aria-hidden="true"></i> Updated 2019-08-23</time><span class="post-meta__separator mobile_hidden">|</span><span class="mobile_hidden"><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/Tutorial/">Tutorial</a><i class="fa fa-angle-right" aria-hidden="true"></i><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/Tutorial/Big-Data/">Big Data</a></span><div class="post-meta-wordcount"><span>Word count: </span><span class="word-count">4.7k</span><span class="post-meta__separator">|</span><span>Reading time: 29 min</span><span class="post-meta__separator">|</span><span>Post View: </span><span id="busuanzi_value_page_pv"></span></div></div></div></div><div class="layout layout_post" id="content-inner">   <article id="post"><div class="article-container" id="post-content"><h1 id="Introduction-to-The-Post"><a href="#Introduction-to-The-Post" class="headerlink" title="Introduction to The Post"></a>Introduction to The Post</h1><p>This post is going to describe how to use the Apache Spark Platform for Machine Learning.  It will start by reviewing the basics of the dataframe data structure.  Then, it will cover the pre-processing to both numeric and text data so that is ready to use with Spark’s MLlib machine learning library.  The post will also describe multiple algorithms for clustering, classification and regression.  In the end, it will briefly describe a recommendation system.</p>
<h1 id="Introduction-to-Spark"><a href="#Introduction-to-Spark" class="headerlink" title="Introduction to Spark"></a>Introduction to Spark</h1><p>Spark is a distributed, data processing platform for big data.  Distributed means Spark runs on a cluster of servers and the data processing means it performs computations such as ETL and modelling.  In the case of Spark, some of the most interesting computations are related to machine learning and data analysis.  Big data is a term broadly applied to data sets that are not easily analyzed on a single server or using older data management systems that were designed to run on a single server.  Spark is becoming increasingly polyglot with support for multiple languages.  Software engineers familiar with Scala and Java can use those languages while data scientists who prefer Python and R can work with those languages.</p>
<p>This post will use Python as programming language.  Spark uses a modular architecture that allows for multiple components or packages.  These include MLlib for machine learning, Spark SQL for relational querying, Spark Streaming for continuous processing of streaming data, and GraphX for graph analysis, such as social network analysis.  Spark is a generalized computation platform designed to manage large data sets.  It’s found use in a wide number of industries and applications, including real-time monitoring of financial data, text analysis related to competitive intelligence and compliance, analyzing how customers use eCommerce sites, and healthcare applications, such as analyzing genomes.</p>
<h1 id="Steps-in-Machine-Learning-Process"><a href="#Steps-in-Machine-Learning-Process" class="headerlink" title="Steps in Machine Learning Process"></a>Steps in Machine Learning Process</h1><p>There are three broad steps in the machine learning process.</p>
<p>The first is preprocessing, which includes collecting, reformatting, and transforming data, so that it’s readily used by machine learning algorithms.</p>
<p>The second step is model building, in which machine learning algorithms are applied to training data to build models.  Models are pieces of code that capture the information implicit in training data.</p>
<p>The last step is validation, in which to measure how well models are performing.  There are multiple ways to measure performance.  The preprocessing phase includes extracting, transforming, and loading data.  This is similar to the ETL process used in business intelligence and data warehousing.</p>
<h1 id="Creating-Spark-Session-and-Basic-Dataframe-Processing"><a href="#Creating-Spark-Session-and-Basic-Dataframe-Processing" class="headerlink" title="Creating Spark Session and Basic Dataframe Processing"></a>Creating Spark Session and Basic Dataframe Processing</h1><p>The following code is going to import all packages to use spark commands:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkContext, SparkConf</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"><span class="keyword">from</span> pyspark.sql.functions <span class="keyword">import</span> to_timestamp</span><br></pre></td></tr></table></figure>

<h2 id="Create-Spark-Session"><a href="#Create-Spark-Session" class="headerlink" title="Create Spark Session"></a>Create Spark Session</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Create Session</span></span><br><span class="line">spark = SparkSession.builder.master(<span class="string">'yarn'</span>).appName(<span class="string">"spark_basic"</span>).getOrCreate()</span><br><span class="line"><span class="comment"># Configure the Session</span></span><br><span class="line">spark.conf.set(<span class="string">"spark.executor.memory"</span>, <span class="string">"8g"</span>)</span><br><span class="line">spark.conf.set(<span class="string">'spark.executor.cores'</span>, <span class="string">'3'</span>)</span><br><span class="line">spark.conf.set(<span class="string">'spark.cores.max'</span>, <span class="string">'3'</span>)</span><br><span class="line">spark.conf.set(<span class="string">"spark.driver.memory"</span>,<span class="string">'8g'</span>)</span><br></pre></td></tr></table></figure>

<h2 id="Basic-Dataframe-Processing"><a href="#Basic-Dataframe-Processing" class="headerlink" title="Basic Dataframe Processing"></a>Basic Dataframe Processing</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Set the file path</span></span><br><span class="line">address = <span class="string">"hdfs://10.22.17.39:9000"</span></span><br><span class="line">sales_path = <span class="string">f"<span class="subst">&#123;address&#125;</span>/data/sales/"</span></span><br></pre></td></tr></table></figure>

<p>There are 3 ways to read csv files:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1st way to read csv file</span></span><br><span class="line">df = spark.read.csv(<span class="string">f"<span class="subst">&#123;sales_path&#125;</span>RK_B_TRANSACTION_WTCTW_201701_000000.csv"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2nd way to read csv file, similar to 3rd way</span></span><br><span class="line">df2 = spark.read.format(<span class="string">"csv"</span>).option(<span class="string">"header"</span>, <span class="string">"true"</span>).load(<span class="string">f"<span class="subst">&#123;sales_path&#125;</span>RK_B_TRANSACTION_WTCTW_201701_000000.csv"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3rd way to read csv file, similar to 2nd way</span></span><br><span class="line"><span class="comment"># Suggested way to read, many options to specify</span></span><br><span class="line">df3 = spark.read.load(<span class="string">f"<span class="subst">&#123;sales_path&#125;</span>RK_B_TRANSACTION_WTCTW_201701_000000.csv"</span>,</span><br><span class="line">                     format=<span class="string">"csv"</span>, sep=<span class="string">"|"</span>, inferSchema=<span class="string">"true"</span>, header=<span class="string">"true"</span>, timestampFormat=<span class="string">"yyyy.MM.dd HH:mm:ss"</span>)</span><br></pre></td></tr></table></figure>

<p>Printing Schema:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Basic</span></span><br><span class="line">df</span><br><span class="line"></span><br><span class="line"><span class="comment"># A bit more details</span></span><br><span class="line">df.schema</span><br><span class="line">display(df3)</span><br><span class="line"></span><br><span class="line"><span class="comment"># A more structured details</span></span><br><span class="line">df.printSchema()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Show data types for each columns</span></span><br><span class="line">df.dtypes</span><br><span class="line"></span><br><span class="line"><span class="comment"># Show a summary of some calculated values like MAX, MIN, MEAN, COUNT for each column</span></span><br><span class="line">df.describe().show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Explain the physical plan for the dataframe</span></span><br><span class="line">df.explain()</span><br></pre></td></tr></table></figure>

<p>Getting Some Contents:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Print column names</span></span><br><span class="line">df.columns</span><br><span class="line"></span><br><span class="line"><span class="comment"># Showing the dataframe</span></span><br><span class="line">df.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Showing the first row in dataframe</span></span><br><span class="line">df.first()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Get first 5 rows</span></span><br><span class="line">df.take(<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Counting the number of rows</span></span><br><span class="line">df.count()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Take only 10% of the data</span></span><br><span class="line">sample_df = df.sample(<span class="literal">False</span>, <span class="number">0.1</span>)</span><br><span class="line">sample_df.count()</span><br></pre></td></tr></table></figure>

<p>Basic Queries:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Filtering Contents</span></span><br><span class="line">emp_mgrs_df = df.filter(<span class="string">"salary &gt;= 100000"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Seleting Columns to Show</span></span><br><span class="line">emp_mgrs_df.select(<span class="string">"salary"</span>).show()</span><br></pre></td></tr></table></figure>

<p>A bit more advanced query examples:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Select unique values within a column and sort it in ascending order</span></span><br><span class="line">df.select(<span class="string">"PRODUCT_KEY"</span>).distinct().orderBy(<span class="string">"PRODUCT_KEY"</span>).show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Filter the type and select some useful columns</span></span><br><span class="line">df.filter(df3[<span class="string">'TRANSACTION_TYPE_NAME'</span>] == <span class="string">'Item'</span>).select(<span class="string">'PRODUCT_KEY'</span>, <span class="string">'TRANSACTION_ID'</span>, <span class="string">'ORDER_NUM'</span>, <span class="string">'ITEM_QUANTITY_VAL'</span>, <span class="string">'ITEM_AMT'</span>, <span class="string">'ITEM_UNIT_PRICE_AMT'</span>, <span class="string">'TRANSACTION_DT'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Select userful columns and group them by the keys, then calculate the sum of quantity for each key and sort it in a decending order.</span></span><br><span class="line">df.select(<span class="string">"PRODUCT_KEY"</span>, <span class="string">"ITEM_QUANTITY_VAL"</span>).groupBy(<span class="string">"PRODUCT_KEY"</span>).sum(<span class="string">"ITEM_QUANTITY_VAL"</span>).sort(<span class="string">"sum(ITEM_QUANTITY_VAL)"</span>, ascending = <span class="literal">False</span>).show()</span><br></pre></td></tr></table></figure>

<p>Some Useful Functions:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># This allow the programme to retrive the results from terminal</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_path</span><span class="params">(path)</span>:</span></span><br><span class="line">    arguments = <span class="string">"hdfs dfs -ls "</span>+ path +<span class="string">" | awk '&#123;print $8&#125;'"</span></span><br><span class="line">    proc = subprocess.Popen(arguments, stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    s_output, s_err = proc.communicate()</span><br><span class="line">    all_files_path = s_output.decode(<span class="string">'utf-8'</span>).split()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> all_files_path</span><br><span class="line"></span><br><span class="line"><span class="comment"># Transform date values and make some new columns to display</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">expand_date_n_sales</span><span class="params">(dataframe)</span>:</span></span><br><span class="line">    filtered_sales = filter_sales(dataframe)</span><br><span class="line">    expand_date_n_sales = filtered_sales.select(<span class="string">"PRODUCT_KEY"</span>, <span class="string">"ITEM_QUANTITY_VAL"</span>, <span class="string">"TRANSACTION_DT"</span>,</span><br><span class="line">                                    date_format(<span class="string">'TRANSACTION_DT'</span>, <span class="string">'Y'</span>).alias(<span class="string">'year'</span>),</span><br><span class="line">                                    date_format(<span class="string">'TRANSACTION_DT'</span>, <span class="string">'M'</span>).alias(<span class="string">'month'</span>),</span><br><span class="line">                                    date_format(<span class="string">'TRANSACTION_DT'</span>, <span class="string">'D'</span>).alias(<span class="string">'day'</span>),</span><br><span class="line">                                    date_format(<span class="string">'TRANSACTION_DT'</span>, <span class="string">'W'</span>).alias(<span class="string">'week_no'</span>))</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> expand_date_n_sales</span><br><span class="line"></span><br><span class="line"><span class="comment"># Loop through all files to get the data and merge together</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_all_cleaned_sales</span><span class="params">(address, path)</span>:</span></span><br><span class="line">    all_files_path = get_path(path)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(all_files_path)):</span><br><span class="line">        <span class="keyword">if</span> i == <span class="number">0</span>:</span><br><span class="line">            first_raw_df = load_data(address, all_files_path[i])</span><br><span class="line">            df = expand_date_n_sales(first_raw_df)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            raw_df = load_data(address, all_files_path[i])</span><br><span class="line">            tmp_df = expand_date_n_sales(raw_df)</span><br><span class="line">            df = df.union(tmp_df)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> df</span><br></pre></td></tr></table></figure>

<h1 id="Components-of-Spark-MLlib"><a href="#Components-of-Spark-MLlib" class="headerlink" title="Components of Spark MLlib"></a>Components of Spark MLlib</h1><p>The MLlib package has three types of functions.</p>
<p>The first is machine learning algorithms.  The set of algorithms currently includes algorithms for classifications, which is for categorizing something, such as a customer likely to leave for a competitor.  Regression, which is used for predicting a numeric value like a home price.  Clustering is used to group similar items together.  Unlike classification, there are no predefined groups, so this is really useful when exploring data.  Finally, there’s topic modeling, which is a way to identify themes in a text.</p>
<p>The second group is workflows.  Workflow components help organize commonly used steps, like pre-processing operations and tuning.  This makes it easy to run a sequence of steps repeatedly while varying some parameters of the process.</p>
<p>Utilities are lower level functions that give you access to distributed linear algebra and statistics functions.</p>
<h1 id="Introduction-to-Preprocessing"><a href="#Introduction-to-Preprocessing" class="headerlink" title="Introduction to Preprocessing"></a>Introduction to Preprocessing</h1><p>There are two types of pre-processing, numeric and text pre-processing.</p>
<h2 id="Numeric"><a href="#Numeric" class="headerlink" title="Numeric"></a>Numeric</h2><h3 id="Normalisation-MinMaxScaler"><a href="#Normalisation-MinMaxScaler" class="headerlink" title="Normalisation (MinMaxScaler)"></a>Normalisation (MinMaxScaler)</h3><p>Normalising maps data values from their original range to the range of zero to one.  It’s used to avoid problems when some attributes have large ranges and others have small ranges.  For example, salaries have a large range, but years of employment has a small range.</p>
<h3 id="Standardisation-StandardScaler"><a href="#Standardisation-StandardScaler" class="headerlink" title="Standardisation (StandardScaler)"></a>Standardisation (StandardScaler)</h3><p>Standardising maps data values from their original range to a range of negative one to one and it also has a mean value of zero.  This transformation creates a normal distribution with a standard deviation of one.  This transforms our data into a bell curve shape formation.  It’s used when attributes have different scales, and the machine learning algorithm you’re using assumes a normal distribution.</p>
<h3 id="Partition-Bucketiser"><a href="#Partition-Bucketiser" class="headerlink" title="Partition (Bucketiser)"></a>Partition (Bucketiser)</h3><p>Partitioning maps data values from continuous values to buckets, like histograms.  Deciles and percentiles are examples of buckets.  It’s useful when you want to work with groups of values instead of a continuous range of values.</p>
<h2 id="Text"><a href="#Text" class="headerlink" title="Text"></a>Text</h2><h3 id="Tokenisation-Tokeniser"><a href="#Tokenisation-Tokeniser" class="headerlink" title="Tokenisation (Tokeniser)"></a>Tokenisation (Tokeniser)</h3><p>This transformation maps text from a single string to a set of tokens, or words. For example, the sentence, quote, “This is a Sentence,” can be mapped into a list of tokens, or words, such as the four word list shown below.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[<span class="string">"This"</span>, <span class="string">"is"</span>, <span class="string">"a"</span>, <span class="string">"sentence"</span>]</span><br></pre></td></tr></table></figure>

<h3 id="Term-Frequency-Inverse-Document-Frequency-TF-IDF-Hashing-TF"><a href="#Term-Frequency-Inverse-Document-Frequency-TF-IDF-Hashing-TF" class="headerlink" title="Term Frequency Inverse Document Frequency (TF-IDF) - (Hashing TF)"></a>Term Frequency Inverse Document Frequency (TF-IDF) - (Hashing TF)</h3><p>This method maps text from a single, typically long string, to a vector, indicating the frequency of each word in a text relative to a group of texts such as a corpus. This transformation is widely used in text classification.  TF-IDF captures the intuition that infrequently used words are more useful for distinguishing categories of text than frequently used words.</p>
<h1 id="Introduction-to-Clustering"><a href="#Introduction-to-Clustering" class="headerlink" title="Introduction to Clustering"></a>Introduction to Clustering</h1><p>Often when working with new data sets, it helps to explore the data and look for macro-level structures such as broad clusters of data.  Clustering algorithms group data into clusters that allow us to see how large data sets can break down into distinct subgroups.  K-means is widely used and works well for finding clusters in small and mid-sized data sets.  For large data sets, the Bisecting K-means algorithms can be faster.</p>
<h2 id="K-means-Clustering"><a href="#K-means-Clustering" class="headerlink" title="K-means Clustering"></a>K-means Clustering</h2><p><strong><em>Don’t forget to create a spark session before using spark!</em></strong></p>
<p>Import some essential spark packages:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.ml.linalg <span class="keyword">import</span> Vectors</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> VectorAssembler</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.clustering <span class="keyword">import</span> KMeans</span><br></pre></td></tr></table></figure>

<p>Create a dataframe:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cluster_df = spark.read.csv(<span class="string">"./ex/Ch03/03_02/clustering_dataset.csv"</span>, header = <span class="literal">True</span>, inferSchema = <span class="literal">True</span>)</span><br><span class="line"><span class="comment"># Select all 75 rows of data</span></span><br><span class="line">cluster_df.show(<span class="number">75</span>)</span><br></pre></td></tr></table></figure>

<p>Transform data to a feature vector:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">vectorAssembler = VectorAssembler(imputCols = [<span class="string">"col1"</span>, <span class="string">"col2"</span>, <span class="string">"col3"</span>], outputCol = <span class="string">"features"</span>)</span><br><span class="line">vcluster_df = vectorAssembler.transform(cluster_df)</span><br></pre></td></tr></table></figure>

<p>Setup K-means algorithm:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Set the cluster number</span></span><br><span class="line">kmeans = KMeans().setK(<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Set where the k-means algorithm starts</span></span><br><span class="line">kmeans = kmeans.setSeed(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Fit the data</span></span><br><span class="line">kmodel = kmeans.fit(vcluster_df)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Find the centers of the clusters</span></span><br><span class="line">centers = kmodel.clusterCenters()</span><br><span class="line"></span><br><span class="line">centers</span><br></pre></td></tr></table></figure>

<p>Output:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[array([<span class="number">35.88461538</span>, <span class="number">31.46153846</span>, <span class="number">34.42307692</span>]),</span><br><span class="line"> array([<span class="number">5.12</span>, <span class="number">5.84</span>, <span class="number">4.84</span>]),</span><br><span class="line"> array([<span class="number">80.</span>        , <span class="number">79.20833333</span>, <span class="number">78.29166667</span>])]</span><br></pre></td></tr></table></figure>

<h2 id="Hierarchical-Clustering"><a href="#Hierarchical-Clustering" class="headerlink" title="Hierarchical Clustering"></a>Hierarchical Clustering</h2><p>Import some essential spark packages:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.ml.clustering <span class="keyword">import</span> BisectingKMeans</span><br></pre></td></tr></table></figure>

<p>Setup Bisecting KMeans algorithm:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">bkmeans = BisectingKMeans().setK(<span class="number">3</span>)</span><br><span class="line">bkmeans = bkmeans.setSeed(<span class="number">1</span>)</span><br><span class="line">bkmodel = bkmeans.fit(vcluster_df)</span><br><span class="line">bkcenters = bkmodel.clusterCenters()</span><br></pre></td></tr></table></figure>

<p>Output:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[array([<span class="number">5.12</span>, <span class="number">5.84</span>, <span class="number">4.84</span>]),</span><br><span class="line"> array([<span class="number">35.88461538</span>, <span class="number">31.46153846</span>, <span class="number">34.42307692</span>]),</span><br><span class="line"> array([<span class="number">80.</span>        , <span class="number">79.20833333</span>, <span class="number">78.29166667</span>])]</span><br></pre></td></tr></table></figure>

<h1 id="Introduction-to-Classification"><a href="#Introduction-to-Classification" class="headerlink" title="Introduction to Classification"></a>Introduction to Classification</h1><p>Classification algorithms are useful when we have datasets that we want to be able to split into different categories.  So, for example, we might have a number of pieces of data that fall into Category A or Category B, and sometimes it’s not so obvious where certain things should fall.  Classification algorithms help us identify boundaries between different categories and make it easy for us to then decide how to assign a new entity to a particular category.</p>
<h2 id="Preprocessing-The-Iris-Dataset"><a href="#Preprocessing-The-Iris-Dataset" class="headerlink" title="Preprocessing The Iris Dataset"></a>Preprocessing The Iris Dataset</h2><p>Import some essential spark packages:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkContext, SparkConf</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"><span class="keyword">from</span> pyspark.sql.functions <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> VectorAssembler</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> StringIndexer</span><br></pre></td></tr></table></figure>

<p>Create A Spark Session:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">spark = SparkSession.builder.master(<span class="string">'local'</span>).appName(<span class="string">"spark_basic"</span>).getOrCreate()</span><br></pre></td></tr></table></figure>

<p>Create Spark Dataframe:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">iris_df = spark.read.csv(<span class="string">"iris.data"</span>, inferSchema = <span class="literal">True</span>)</span><br><span class="line">iris_df.show()</span><br></pre></td></tr></table></figure>

<p>Output:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">+---+---+---+---+-----------+</span><br><span class="line">|_c0|_c1|_c2|_c3|        _c4|</span><br><span class="line">+---+---+---+---+-----------+</span><br><span class="line">|<span class="number">5.1</span>|<span class="number">3.5</span>|<span class="number">1.4</span>|<span class="number">0.2</span>|Iris-setosa|</span><br><span class="line">|<span class="number">4.9</span>|<span class="number">3.0</span>|<span class="number">1.4</span>|<span class="number">0.2</span>|Iris-setosa|</span><br><span class="line">|<span class="number">4.7</span>|<span class="number">3.2</span>|<span class="number">1.3</span>|<span class="number">0.2</span>|Iris-setosa|</span><br><span class="line">|<span class="number">4.6</span>|<span class="number">3.1</span>|<span class="number">1.5</span>|<span class="number">0.2</span>|Iris-setosa|</span><br><span class="line">|<span class="number">5.0</span>|<span class="number">3.6</span>|<span class="number">1.4</span>|<span class="number">0.2</span>|Iris-setosa|</span><br><span class="line">|<span class="number">5.4</span>|<span class="number">3.9</span>|<span class="number">1.7</span>|<span class="number">0.4</span>|Iris-setosa|</span><br><span class="line">|<span class="number">4.6</span>|<span class="number">3.4</span>|<span class="number">1.4</span>|<span class="number">0.3</span>|Iris-setosa|</span><br><span class="line">|<span class="number">5.0</span>|<span class="number">3.4</span>|<span class="number">1.5</span>|<span class="number">0.2</span>|Iris-setosa|</span><br><span class="line">|<span class="number">4.4</span>|<span class="number">2.9</span>|<span class="number">1.4</span>|<span class="number">0.2</span>|Iris-setosa|</span><br><span class="line">|<span class="number">4.9</span>|<span class="number">3.1</span>|<span class="number">1.5</span>|<span class="number">0.1</span>|Iris-setosa|</span><br><span class="line">|<span class="number">5.4</span>|<span class="number">3.7</span>|<span class="number">1.5</span>|<span class="number">0.2</span>|Iris-setosa|</span><br><span class="line">|<span class="number">4.8</span>|<span class="number">3.4</span>|<span class="number">1.6</span>|<span class="number">0.2</span>|Iris-setosa|</span><br><span class="line">|<span class="number">4.8</span>|<span class="number">3.0</span>|<span class="number">1.4</span>|<span class="number">0.1</span>|Iris-setosa|</span><br><span class="line">|<span class="number">4.3</span>|<span class="number">3.0</span>|<span class="number">1.1</span>|<span class="number">0.1</span>|Iris-setosa|</span><br><span class="line">|<span class="number">5.8</span>|<span class="number">4.0</span>|<span class="number">1.2</span>|<span class="number">0.2</span>|Iris-setosa|</span><br><span class="line">|<span class="number">5.7</span>|<span class="number">4.4</span>|<span class="number">1.5</span>|<span class="number">0.4</span>|Iris-setosa|</span><br><span class="line">|<span class="number">5.4</span>|<span class="number">3.9</span>|<span class="number">1.3</span>|<span class="number">0.4</span>|Iris-setosa|</span><br><span class="line">|<span class="number">5.1</span>|<span class="number">3.5</span>|<span class="number">1.4</span>|<span class="number">0.3</span>|Iris-setosa|</span><br><span class="line">|<span class="number">5.7</span>|<span class="number">3.8</span>|<span class="number">1.7</span>|<span class="number">0.3</span>|Iris-setosa|</span><br><span class="line">|<span class="number">5.1</span>|<span class="number">3.8</span>|<span class="number">1.5</span>|<span class="number">0.3</span>|Iris-setosa|</span><br><span class="line">+---+---+---+---+-----------+</span><br><span class="line">only showing top <span class="number">20</span> rows</span><br></pre></td></tr></table></figure>

<p>Rename all columns:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">iris_df = iris_df.select(col(<span class="string">"_c0"</span>).alias(<span class="string">"sepal_length"</span>),</span><br><span class="line">                         col(<span class="string">"_c1"</span>).alias(<span class="string">"sepal_width"</span>),</span><br><span class="line">                         col(<span class="string">"_c2"</span>).alias(<span class="string">"petal_length"</span>),</span><br><span class="line">                         col(<span class="string">"_c3"</span>).alias(<span class="string">"petal_width"</span>),</span><br><span class="line">                         col(<span class="string">"_c4"</span>).alias(<span class="string">"species"</span>)</span><br><span class="line">                        )</span><br><span class="line"></span><br><span class="line">iris_df.show()</span><br></pre></td></tr></table></figure>

<p>Output:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">+------------+-----------+------------+-----------+-----------+</span><br><span class="line">|sepal_length|sepal_width|petal_length|petal_width|    species|</span><br><span class="line">+------------+-----------+------------+-----------+-----------+</span><br><span class="line">|         <span class="number">5.1</span>|        <span class="number">3.5</span>|         <span class="number">1.4</span>|        <span class="number">0.2</span>|Iris-setosa|</span><br><span class="line">|         <span class="number">4.9</span>|        <span class="number">3.0</span>|         <span class="number">1.4</span>|        <span class="number">0.2</span>|Iris-setosa|</span><br><span class="line">|         <span class="number">4.7</span>|        <span class="number">3.2</span>|         <span class="number">1.3</span>|        <span class="number">0.2</span>|Iris-setosa|</span><br><span class="line">|         <span class="number">4.6</span>|        <span class="number">3.1</span>|         <span class="number">1.5</span>|        <span class="number">0.2</span>|Iris-setosa|</span><br><span class="line">|         <span class="number">5.0</span>|        <span class="number">3.6</span>|         <span class="number">1.4</span>|        <span class="number">0.2</span>|Iris-setosa|</span><br><span class="line">|         <span class="number">5.4</span>|        <span class="number">3.9</span>|         <span class="number">1.7</span>|        <span class="number">0.4</span>|Iris-setosa|</span><br><span class="line">|         <span class="number">4.6</span>|        <span class="number">3.4</span>|         <span class="number">1.4</span>|        <span class="number">0.3</span>|Iris-setosa|</span><br><span class="line">|         <span class="number">5.0</span>|        <span class="number">3.4</span>|         <span class="number">1.5</span>|        <span class="number">0.2</span>|Iris-setosa|</span><br><span class="line">|         <span class="number">4.4</span>|        <span class="number">2.9</span>|         <span class="number">1.4</span>|        <span class="number">0.2</span>|Iris-setosa|</span><br><span class="line">|         <span class="number">4.9</span>|        <span class="number">3.1</span>|         <span class="number">1.5</span>|        <span class="number">0.1</span>|Iris-setosa|</span><br><span class="line">|         <span class="number">5.4</span>|        <span class="number">3.7</span>|         <span class="number">1.5</span>|        <span class="number">0.2</span>|Iris-setosa|</span><br><span class="line">|         <span class="number">4.8</span>|        <span class="number">3.4</span>|         <span class="number">1.6</span>|        <span class="number">0.2</span>|Iris-setosa|</span><br><span class="line">|         <span class="number">4.8</span>|        <span class="number">3.0</span>|         <span class="number">1.4</span>|        <span class="number">0.1</span>|Iris-setosa|</span><br><span class="line">|         <span class="number">4.3</span>|        <span class="number">3.0</span>|         <span class="number">1.1</span>|        <span class="number">0.1</span>|Iris-setosa|</span><br><span class="line">|         <span class="number">5.8</span>|        <span class="number">4.0</span>|         <span class="number">1.2</span>|        <span class="number">0.2</span>|Iris-setosa|</span><br><span class="line">|         <span class="number">5.7</span>|        <span class="number">4.4</span>|         <span class="number">1.5</span>|        <span class="number">0.4</span>|Iris-setosa|</span><br><span class="line">|         <span class="number">5.4</span>|        <span class="number">3.9</span>|         <span class="number">1.3</span>|        <span class="number">0.4</span>|Iris-setosa|</span><br><span class="line">|         <span class="number">5.1</span>|        <span class="number">3.5</span>|         <span class="number">1.4</span>|        <span class="number">0.3</span>|Iris-setosa|</span><br><span class="line">|         <span class="number">5.7</span>|        <span class="number">3.8</span>|         <span class="number">1.7</span>|        <span class="number">0.3</span>|Iris-setosa|</span><br><span class="line">|         <span class="number">5.1</span>|        <span class="number">3.8</span>|         <span class="number">1.5</span>|        <span class="number">0.3</span>|Iris-setosa|</span><br><span class="line">+------------+-----------+------------+-----------+-----------+</span><br></pre></td></tr></table></figure>

<p>Transform the dataframe into vector structure:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">vectorAssembler = VectorAssembler(inputCols = [<span class="string">"sepal_length"</span>, <span class="string">"sepal_width"</span>, <span class="string">"petal_length"</span>, <span class="string">"petal_width"</span>], outputCol = <span class="string">"features"</span>)</span><br><span class="line">viris_df = vectorAssembler.transform(iris_df)</span><br><span class="line"></span><br><span class="line">viris_df.show()</span><br></pre></td></tr></table></figure>

<p>Output:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">+------------+-----------+------------+-----------+-----------+-----------------+</span><br><span class="line">|sepal_length|sepal_width|petal_length|petal_width|    species|         features|</span><br><span class="line">+------------+-----------+------------+-----------+-----------+-----------------+</span><br><span class="line">|         <span class="number">5.1</span>|        <span class="number">3.5</span>|         <span class="number">1.4</span>|        <span class="number">0.2</span>|Iris-setosa|[<span class="number">5.1</span>,<span class="number">3.5</span>,<span class="number">1.4</span>,<span class="number">0.2</span>]|</span><br><span class="line">|         <span class="number">4.9</span>|        <span class="number">3.0</span>|         <span class="number">1.4</span>|        <span class="number">0.2</span>|Iris-setosa|[<span class="number">4.9</span>,<span class="number">3.0</span>,<span class="number">1.4</span>,<span class="number">0.2</span>]|</span><br><span class="line">|         <span class="number">4.7</span>|        <span class="number">3.2</span>|         <span class="number">1.3</span>|        <span class="number">0.2</span>|Iris-setosa|[<span class="number">4.7</span>,<span class="number">3.2</span>,<span class="number">1.3</span>,<span class="number">0.2</span>]|</span><br><span class="line">|         <span class="number">4.6</span>|        <span class="number">3.1</span>|         <span class="number">1.5</span>|        <span class="number">0.2</span>|Iris-setosa|[<span class="number">4.6</span>,<span class="number">3.1</span>,<span class="number">1.5</span>,<span class="number">0.2</span>]|</span><br><span class="line">|         <span class="number">5.0</span>|        <span class="number">3.6</span>|         <span class="number">1.4</span>|        <span class="number">0.2</span>|Iris-setosa|[<span class="number">5.0</span>,<span class="number">3.6</span>,<span class="number">1.4</span>,<span class="number">0.2</span>]|</span><br><span class="line">|         <span class="number">5.4</span>|        <span class="number">3.9</span>|         <span class="number">1.7</span>|        <span class="number">0.4</span>|Iris-setosa|[<span class="number">5.4</span>,<span class="number">3.9</span>,<span class="number">1.7</span>,<span class="number">0.4</span>]|</span><br><span class="line">|         <span class="number">4.6</span>|        <span class="number">3.4</span>|         <span class="number">1.4</span>|        <span class="number">0.3</span>|Iris-setosa|[<span class="number">4.6</span>,<span class="number">3.4</span>,<span class="number">1.4</span>,<span class="number">0.3</span>]|</span><br><span class="line">|         <span class="number">5.0</span>|        <span class="number">3.4</span>|         <span class="number">1.5</span>|        <span class="number">0.2</span>|Iris-setosa|[<span class="number">5.0</span>,<span class="number">3.4</span>,<span class="number">1.5</span>,<span class="number">0.2</span>]|</span><br><span class="line">|         <span class="number">4.4</span>|        <span class="number">2.9</span>|         <span class="number">1.4</span>|        <span class="number">0.2</span>|Iris-setosa|[<span class="number">4.4</span>,<span class="number">2.9</span>,<span class="number">1.4</span>,<span class="number">0.2</span>]|</span><br><span class="line">|         <span class="number">4.9</span>|        <span class="number">3.1</span>|         <span class="number">1.5</span>|        <span class="number">0.1</span>|Iris-setosa|[<span class="number">4.9</span>,<span class="number">3.1</span>,<span class="number">1.5</span>,<span class="number">0.1</span>]|</span><br><span class="line">|         <span class="number">5.4</span>|        <span class="number">3.7</span>|         <span class="number">1.5</span>|        <span class="number">0.2</span>|Iris-setosa|[<span class="number">5.4</span>,<span class="number">3.7</span>,<span class="number">1.5</span>,<span class="number">0.2</span>]|</span><br><span class="line">|         <span class="number">4.8</span>|        <span class="number">3.4</span>|         <span class="number">1.6</span>|        <span class="number">0.2</span>|Iris-setosa|[<span class="number">4.8</span>,<span class="number">3.4</span>,<span class="number">1.6</span>,<span class="number">0.2</span>]|</span><br><span class="line">|         <span class="number">4.8</span>|        <span class="number">3.0</span>|         <span class="number">1.4</span>|        <span class="number">0.1</span>|Iris-setosa|[<span class="number">4.8</span>,<span class="number">3.0</span>,<span class="number">1.4</span>,<span class="number">0.1</span>]|</span><br><span class="line">|         <span class="number">4.3</span>|        <span class="number">3.0</span>|         <span class="number">1.1</span>|        <span class="number">0.1</span>|Iris-setosa|[<span class="number">4.3</span>,<span class="number">3.0</span>,<span class="number">1.1</span>,<span class="number">0.1</span>]|</span><br><span class="line">|         <span class="number">5.8</span>|        <span class="number">4.0</span>|         <span class="number">1.2</span>|        <span class="number">0.2</span>|Iris-setosa|[<span class="number">5.8</span>,<span class="number">4.0</span>,<span class="number">1.2</span>,<span class="number">0.2</span>]|</span><br><span class="line">|         <span class="number">5.7</span>|        <span class="number">4.4</span>|         <span class="number">1.5</span>|        <span class="number">0.4</span>|Iris-setosa|[<span class="number">5.7</span>,<span class="number">4.4</span>,<span class="number">1.5</span>,<span class="number">0.4</span>]|</span><br><span class="line">|         <span class="number">5.4</span>|        <span class="number">3.9</span>|         <span class="number">1.3</span>|        <span class="number">0.4</span>|Iris-setosa|[<span class="number">5.4</span>,<span class="number">3.9</span>,<span class="number">1.3</span>,<span class="number">0.4</span>]|</span><br><span class="line">|         <span class="number">5.1</span>|        <span class="number">3.5</span>|         <span class="number">1.4</span>|        <span class="number">0.3</span>|Iris-setosa|[<span class="number">5.1</span>,<span class="number">3.5</span>,<span class="number">1.4</span>,<span class="number">0.3</span>]|</span><br><span class="line">|         <span class="number">5.7</span>|        <span class="number">3.8</span>|         <span class="number">1.7</span>|        <span class="number">0.3</span>|Iris-setosa|[<span class="number">5.7</span>,<span class="number">3.8</span>,<span class="number">1.7</span>,<span class="number">0.3</span>]|</span><br><span class="line">|         <span class="number">5.1</span>|        <span class="number">3.8</span>|         <span class="number">1.5</span>|        <span class="number">0.3</span>|Iris-setosa|[<span class="number">5.1</span>,<span class="number">3.8</span>,<span class="number">1.5</span>,<span class="number">0.3</span>]|</span><br><span class="line">+------------+-----------+------------+-----------+-----------+-----------------+</span><br></pre></td></tr></table></figure>

<p>Convert string value of species into numeric values:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">indexer = StringIndexer(inputCol = <span class="string">"species"</span>, outputCol = <span class="string">"label"</span>)</span><br><span class="line">iviris_df = indexer.fit(viris_df).transform(viris_df)</span><br><span class="line"></span><br><span class="line">iviris_df.show()</span><br></pre></td></tr></table></figure>

<p>Output:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">+------------+-----------+------------+-----------+-----------+-----------------+-----+</span><br><span class="line">|sepal_length|sepal_width|petal_length|petal_width|    species|         features|label|</span><br><span class="line">+------------+-----------+------------+-----------+-----------+-----------------+-----+</span><br><span class="line">|         <span class="number">5.1</span>|        <span class="number">3.5</span>|         <span class="number">1.4</span>|        <span class="number">0.2</span>|Iris-setosa|[<span class="number">5.1</span>,<span class="number">3.5</span>,<span class="number">1.4</span>,<span class="number">0.2</span>]|  <span class="number">0.0</span>|</span><br><span class="line">|         <span class="number">4.9</span>|        <span class="number">3.0</span>|         <span class="number">1.4</span>|        <span class="number">0.2</span>|Iris-setosa|[<span class="number">4.9</span>,<span class="number">3.0</span>,<span class="number">1.4</span>,<span class="number">0.2</span>]|  <span class="number">0.0</span>|</span><br><span class="line">|         <span class="number">4.7</span>|        <span class="number">3.2</span>|         <span class="number">1.3</span>|        <span class="number">0.2</span>|Iris-setosa|[<span class="number">4.7</span>,<span class="number">3.2</span>,<span class="number">1.3</span>,<span class="number">0.2</span>]|  <span class="number">0.0</span>|</span><br><span class="line">|         <span class="number">4.6</span>|        <span class="number">3.1</span>|         <span class="number">1.5</span>|        <span class="number">0.2</span>|Iris-setosa|[<span class="number">4.6</span>,<span class="number">3.1</span>,<span class="number">1.5</span>,<span class="number">0.2</span>]|  <span class="number">0.0</span>|</span><br><span class="line">|         <span class="number">5.0</span>|        <span class="number">3.6</span>|         <span class="number">1.4</span>|        <span class="number">0.2</span>|Iris-setosa|[<span class="number">5.0</span>,<span class="number">3.6</span>,<span class="number">1.4</span>,<span class="number">0.2</span>]|  <span class="number">0.0</span>|</span><br><span class="line">|         <span class="number">5.4</span>|        <span class="number">3.9</span>|         <span class="number">1.7</span>|        <span class="number">0.4</span>|Iris-setosa|[<span class="number">5.4</span>,<span class="number">3.9</span>,<span class="number">1.7</span>,<span class="number">0.4</span>]|  <span class="number">0.0</span>|</span><br><span class="line">|         <span class="number">4.6</span>|        <span class="number">3.4</span>|         <span class="number">1.4</span>|        <span class="number">0.3</span>|Iris-setosa|[<span class="number">4.6</span>,<span class="number">3.4</span>,<span class="number">1.4</span>,<span class="number">0.3</span>]|  <span class="number">0.0</span>|</span><br><span class="line">|         <span class="number">5.0</span>|        <span class="number">3.4</span>|         <span class="number">1.5</span>|        <span class="number">0.2</span>|Iris-setosa|[<span class="number">5.0</span>,<span class="number">3.4</span>,<span class="number">1.5</span>,<span class="number">0.2</span>]|  <span class="number">0.0</span>|</span><br><span class="line">|         <span class="number">4.4</span>|        <span class="number">2.9</span>|         <span class="number">1.4</span>|        <span class="number">0.2</span>|Iris-setosa|[<span class="number">4.4</span>,<span class="number">2.9</span>,<span class="number">1.4</span>,<span class="number">0.2</span>]|  <span class="number">0.0</span>|</span><br><span class="line">|         <span class="number">4.9</span>|        <span class="number">3.1</span>|         <span class="number">1.5</span>|        <span class="number">0.1</span>|Iris-setosa|[<span class="number">4.9</span>,<span class="number">3.1</span>,<span class="number">1.5</span>,<span class="number">0.1</span>]|  <span class="number">0.0</span>|</span><br><span class="line">|         <span class="number">5.4</span>|        <span class="number">3.7</span>|         <span class="number">1.5</span>|        <span class="number">0.2</span>|Iris-setosa|[<span class="number">5.4</span>,<span class="number">3.7</span>,<span class="number">1.5</span>,<span class="number">0.2</span>]|  <span class="number">0.0</span>|</span><br><span class="line">|         <span class="number">4.8</span>|        <span class="number">3.4</span>|         <span class="number">1.6</span>|        <span class="number">0.2</span>|Iris-setosa|[<span class="number">4.8</span>,<span class="number">3.4</span>,<span class="number">1.6</span>,<span class="number">0.2</span>]|  <span class="number">0.0</span>|</span><br><span class="line">|         <span class="number">4.8</span>|        <span class="number">3.0</span>|         <span class="number">1.4</span>|        <span class="number">0.1</span>|Iris-setosa|[<span class="number">4.8</span>,<span class="number">3.0</span>,<span class="number">1.4</span>,<span class="number">0.1</span>]|  <span class="number">0.0</span>|</span><br><span class="line">|         <span class="number">4.3</span>|        <span class="number">3.0</span>|         <span class="number">1.1</span>|        <span class="number">0.1</span>|Iris-setosa|[<span class="number">4.3</span>,<span class="number">3.0</span>,<span class="number">1.1</span>,<span class="number">0.1</span>]|  <span class="number">0.0</span>|</span><br><span class="line">|         <span class="number">5.8</span>|        <span class="number">4.0</span>|         <span class="number">1.2</span>|        <span class="number">0.2</span>|Iris-setosa|[<span class="number">5.8</span>,<span class="number">4.0</span>,<span class="number">1.2</span>,<span class="number">0.2</span>]|  <span class="number">0.0</span>|</span><br><span class="line">|         <span class="number">5.7</span>|        <span class="number">4.4</span>|         <span class="number">1.5</span>|        <span class="number">0.4</span>|Iris-setosa|[<span class="number">5.7</span>,<span class="number">4.4</span>,<span class="number">1.5</span>,<span class="number">0.4</span>]|  <span class="number">0.0</span>|</span><br><span class="line">|         <span class="number">5.4</span>|        <span class="number">3.9</span>|         <span class="number">1.3</span>|        <span class="number">0.4</span>|Iris-setosa|[<span class="number">5.4</span>,<span class="number">3.9</span>,<span class="number">1.3</span>,<span class="number">0.4</span>]|  <span class="number">0.0</span>|</span><br><span class="line">|         <span class="number">5.1</span>|        <span class="number">3.5</span>|         <span class="number">1.4</span>|        <span class="number">0.3</span>|Iris-setosa|[<span class="number">5.1</span>,<span class="number">3.5</span>,<span class="number">1.4</span>,<span class="number">0.3</span>]|  <span class="number">0.0</span>|</span><br><span class="line">|         <span class="number">5.7</span>|        <span class="number">3.8</span>|         <span class="number">1.7</span>|        <span class="number">0.3</span>|Iris-setosa|[<span class="number">5.7</span>,<span class="number">3.8</span>,<span class="number">1.7</span>,<span class="number">0.3</span>]|  <span class="number">0.0</span>|</span><br><span class="line">|         <span class="number">5.1</span>|        <span class="number">3.8</span>|         <span class="number">1.5</span>|        <span class="number">0.3</span>|Iris-setosa|[<span class="number">5.1</span>,<span class="number">3.8</span>,<span class="number">1.5</span>,<span class="number">0.3</span>]|  <span class="number">0.0</span>|</span><br><span class="line">+------------+-----------+------------+-----------+-----------+-----------------+-----+</span><br></pre></td></tr></table></figure>

<h2 id="Naive-Bayes-Classification"><a href="#Naive-Bayes-Classification" class="headerlink" title="Naive Bayes Classification"></a>Naive Bayes Classification</h2><p>Import some essential spark packages:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.ml.classification <span class="keyword">import</span> NaiveBayes</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.evaluation <span class="keyword">import</span> MulticlassClassificationEvaluator</span><br></pre></td></tr></table></figure>

<p>Split the dataset into train and test datasets:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">splits = iviris_df.randomSplit([<span class="number">0.6</span>, <span class="number">0.4</span>], <span class="number">1</span>)</span><br><span class="line">train_df = splits[<span class="number">0</span>]</span><br><span class="line">test_df = splits[<span class="number">1</span>]</span><br></pre></td></tr></table></figure>

<p>Train the model using Naive Bayes Classifier and make the prediction:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">nb = NaiveBayes(modelType = <span class="string">"multinomial"</span>)</span><br><span class="line">nbmodel = nb.fit(train_df)</span><br><span class="line"></span><br><span class="line">predictions_df = nbmodel.transform(test_df)</span><br><span class="line">predictions_df.take(<span class="number">1</span>)</span><br></pre></td></tr></table></figure>

<p>Output:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[Row(sepal_length=<span class="number">4.5</span>, sepal_width=<span class="number">2.3</span>, petal_length=<span class="number">1.3</span>, petal_width=<span class="number">0.3</span>, species=<span class="string">'Iris-setosa'</span>, features=DenseVector([<span class="number">4.5</span>, <span class="number">2.3</span>, <span class="number">1.3</span>, <span class="number">0.3</span>]), label=<span class="number">0.0</span>, rawPrediction=DenseVector([<span class="number">-10.3605</span>, <span class="number">-11.0141</span>, <span class="number">-11.7112</span>]), probability=DenseVector([<span class="number">0.562</span>, <span class="number">0.2924</span>, <span class="number">0.1456</span>]), prediction=<span class="number">0.0</span>)]</span><br></pre></td></tr></table></figure>

<p>Evaluate the accuracy:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">evaluator = MulticlassClassificationEvaluator(labelCol = <span class="string">"label"</span>, predictionCol = <span class="string">"prediction"</span>, metricName = <span class="string">"accuracy"</span>)</span><br><span class="line">nbaccuarcy = evaluator.evaluate(predictions_df)</span><br><span class="line"></span><br><span class="line">nbaccuarcy</span><br></pre></td></tr></table></figure>

<p>Output:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0.5862068965517241</span></span><br></pre></td></tr></table></figure>

<h2 id="Multilayer-Perceptron-Classification"><a href="#Multilayer-Perceptron-Classification" class="headerlink" title="Multilayer Perceptron Classification"></a>Multilayer Perceptron Classification</h2><p>Import some essential spark packages:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.ml.classification <span class="keyword">import</span> MultilayerPerceptronClassifier</span><br></pre></td></tr></table></figure>

<p>Set the layers and do some training using Multilayer Perceptron Classifier as well as making predictions:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Have 4 layers multilayer perceptron,</span></span><br><span class="line"><span class="comment"># the input is 4 neurons, two hidden layers are 5 neurons each and output layer has 3 neurons</span></span><br><span class="line">layers = [<span class="number">4</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">3</span>]</span><br><span class="line"></span><br><span class="line">mlp = MultilayerPerceptronClassifier(layers = layers, seed = <span class="number">1</span>)</span><br><span class="line">mlp_model = mlp.fit(train_df)</span><br><span class="line">mlp_predictions = mlp_model.transform(test_df)</span><br></pre></td></tr></table></figure>

<p>Evaluate the result:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">mlp_evaluator = MulticlassClassificationEvaluator(metricName = <span class="string">"accuracy"</span>)</span><br><span class="line">mlp_accuracy = mlp_evaluator.evaluate(mlp_predictions)</span><br><span class="line"></span><br><span class="line">mlp_accuracy</span><br></pre></td></tr></table></figure>

<p>Output:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0.9482758620689655</span></span><br></pre></td></tr></table></figure>

<h2 id="Decision-Trees-Classification"><a href="#Decision-Trees-Classification" class="headerlink" title="Decision Trees Classification"></a>Decision Trees Classification</h2><p>Import some essential spark packages:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.ml.classification <span class="keyword">import</span> DecisionTreeClassifier</span><br></pre></td></tr></table></figure>

<p>Train the model using Decision Trees Claccifier as well as making predictions:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">dt = DecisionTreeClassifier(labelCol = <span class="string">"label"</span>, featuresCol = <span class="string">"features"</span>)</span><br><span class="line">dt_model = dt.fit(train_df)</span><br><span class="line"></span><br><span class="line">dt_predictions = dt_model.transform(test_df)</span><br></pre></td></tr></table></figure>

<p>Evaluate the result:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">dt_evaluator = MulticlassClassificationEvaluator(labelCol = <span class="string">"label"</span>, predictionCol = <span class="string">"prediction"</span>, metricName = <span class="string">"accuracy"</span>)</span><br><span class="line">dt_accuracy = dt_evaluator.evaluate(dt_predictions)</span><br><span class="line"></span><br><span class="line">dt_accuracy</span><br></pre></td></tr></table></figure>

<p>Output:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0.9310344827586207</span></span><br></pre></td></tr></table></figure>

<h1 id="Introduction-to-Regresssion"><a href="#Introduction-to-Regresssion" class="headerlink" title="Introduction to Regresssion"></a>Introduction to Regresssion</h1><p>Regression techniques allow us to make predictions about numeric values.  For example, if we have a product and the price of that product has been steadily rising over time, we might want to be able to estimate what the price will be in the future.  Now we could look at prices over a period of time and try and fit a line to those price points over time.  That line is useful because it goes out into the future and we can use it to make projections about what the price might be at some future point.</p>
<h2 id="Pre-processing-The-Dataset"><a href="#Pre-processing-The-Dataset" class="headerlink" title="Pre-processing The Dataset"></a>Pre-processing The Dataset</h2><p>Import some essential spark packages:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkContext, SparkConf</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br></pre></td></tr></table></figure>

<p>Create a spark session:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">spark = SparkSession.builder.master(<span class="string">'local'</span>).appName(<span class="string">"spark_basic"</span>).getOrCreate()</span><br></pre></td></tr></table></figure>

<p>Read the CSV file:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pp_df = spark.read.csv(<span class="string">"power_plant.csv"</span>)</span><br><span class="line">pp_df</span><br></pre></td></tr></table></figure>

<p>Output:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DataFrame[_c0: string, _c1: string, _c2: string, _c3: string, _c4: string]</span><br></pre></td></tr></table></figure>

<p>Read the CSV file again correctly:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pp_df = spark.read.csv(<span class="string">"power_plant.csv"</span>, header = <span class="literal">True</span>, inferSchema = <span class="literal">True</span>)</span><br><span class="line">pp_df</span><br></pre></td></tr></table></figure>

<p>Output:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DataFrame[AT: double, V: double, AP: double, RH: double, PE: double]</span><br></pre></td></tr></table></figure>

<p>Creating a feature vector:</p>
<p>Import some essential spark packages:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> VectorAssembler</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">vectorAssembler = VectorAssembler(inputCols = [<span class="string">"AT"</span>, <span class="string">"V"</span>, <span class="string">"AP"</span>, <span class="string">"RH"</span>], outputCol = <span class="string">"features"</span>)</span><br><span class="line">vpp_df = vectorAssembler.transform(pp_df)</span><br><span class="line"></span><br><span class="line">vpp_df.take(<span class="number">1</span>)</span><br></pre></td></tr></table></figure>

<p>Output:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[Row(AT=<span class="number">14.96</span>, V=<span class="number">41.76</span>, AP=<span class="number">1024.07</span>, RH=<span class="number">73.17</span>, PE=<span class="number">463.26</span>, features=DenseVector([<span class="number">14.96</span>, <span class="number">41.76</span>, <span class="number">1024.07</span>, <span class="number">73.17</span>]))]</span><br></pre></td></tr></table></figure>

<h2 id="Linear-Regression"><a href="#Linear-Regression" class="headerlink" title="Linear Regression"></a>Linear Regression</h2><p>Import some essential spark packages:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.ml.regression <span class="keyword">import</span> LinearRegression</span><br></pre></td></tr></table></figure>

<p>Train the model using Linear Regression:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">lr = LinearRegression(featuresCol = <span class="string">"features"</span>, labelCol = <span class="string">"PE"</span>)</span><br><span class="line">lr_model = lr.fit(vpp_df)</span><br></pre></td></tr></table></figure>

<p>Coefficients:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lr_model.coefficients</span><br></pre></td></tr></table></figure>

<p>Output:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DenseVector([<span class="number">-1.9775</span>, <span class="number">-0.2339</span>, <span class="number">0.0621</span>, <span class="number">-0.1581</span>])</span><br></pre></td></tr></table></figure>

<p>Intercept:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lr_model.intercept</span><br></pre></td></tr></table></figure>

<p>Output:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">454.6092744523414</span></span><br></pre></td></tr></table></figure>

<p>Root Mean Squared Error:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lr_model.summary.rootMeanSquaredError</span><br></pre></td></tr></table></figure>

<p>Output:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">4.557126016749488</span></span><br></pre></td></tr></table></figure>

<p>Save the model:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lr_model.save(<span class="string">"lr1.model"</span>)</span><br></pre></td></tr></table></figure>

<h2 id="Decision-Tree-Regression"><a href="#Decision-Tree-Regression" class="headerlink" title="Decision Tree Regression"></a>Decision Tree Regression</h2><p>Import some essential spark packages:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.ml.regression <span class="keyword">import</span> DecisionTreeRegressor</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.evaluation <span class="keyword">import</span> RegressionEvaluator</span><br></pre></td></tr></table></figure>

<p>Split the dataset into train and test dataset:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">splits = vpp_df.randomSplit([<span class="number">0.7</span>, <span class="number">0.3</span>])</span><br><span class="line"></span><br><span class="line">train_df = splits[<span class="number">0</span>]</span><br><span class="line">test_df = splits[<span class="number">1</span>]</span><br></pre></td></tr></table></figure>

<p>Train the model and make the predictions using Decision Tree Regression:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">dt = DecisionTreeRegressor(featuresCol = <span class="string">"features"</span>, labelCol = <span class="string">"PE"</span>)</span><br><span class="line">dt_model = dt.fit(train_df)</span><br><span class="line"></span><br><span class="line">dt_predictions = dt_model.transform(test_df)</span><br></pre></td></tr></table></figure>

<p>Evaluate the result:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">dt_evaluator = RegressionEvaluator(labelCol = <span class="string">"PE"</span>, predictionCol = <span class="string">"prediction"</span>, metricName = <span class="string">"rmse"</span>)</span><br><span class="line">rmse = dt_evaluator.evaluate(dt_predictions)</span><br><span class="line"></span><br><span class="line">rmse</span><br></pre></td></tr></table></figure>

<p>Output:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">4.459494278528065</span></span><br></pre></td></tr></table></figure>

<h2 id="Gradient-boosted-Tree-Regression"><a href="#Gradient-boosted-Tree-Regression" class="headerlink" title="Gradient-boosted Tree Regression"></a>Gradient-boosted Tree Regression</h2><p>Import some essential spark packages:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.ml.regression <span class="keyword">import</span> GBTRegressor</span><br></pre></td></tr></table></figure>

<p>Train the model and make the predictions using Gradient-boosted Tree Regression:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">gbt = GBTRegressor(featuresCol = <span class="string">"features"</span>, labelCol = <span class="string">"PE"</span>)</span><br><span class="line">gbt_model = gbt.fit(train_df)</span><br><span class="line"></span><br><span class="line">gbt_predictions = gbt_model.transform(test_df)</span><br></pre></td></tr></table></figure>

<p>Evaluate the result:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">gbt_evaluator = RegressionEvaluator(labelCol = <span class="string">"PE"</span>, predictionCol = <span class="string">"prediction"</span>, metricName = <span class="string">"rmse"</span>)</span><br><span class="line">gbt_rmse = gbt_evaluator.evaluate(gbt_predictions)</span><br><span class="line"></span><br><span class="line">gbt_rmse</span><br></pre></td></tr></table></figure>

<p>Output:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">3.976988494544201</span></span><br></pre></td></tr></table></figure>

<h1 id="Understand-Recommendation-Systems"><a href="#Understand-Recommendation-Systems" class="headerlink" title="Understand Recommendation Systems"></a>Understand Recommendation Systems</h1><p>A common problem in machine learning is making recommendations.  There’s two general ways of doing this.  One is called Collaborative Filtering. Let’s imagine you run an online bookstore, and you have a number of customers.  And these customers all like reading both the brown book and the red book.  Now a new customer comes along and indicates that they really enjoyed reading the red book.  What other books can we recommend to them? Definitely the brown book, since other people who have read the red book also enjoy reading the brown book.  This is an example of collaborative filtering.  Another way to make recommendations is based on the properties of the items that you’re working with. For example, if we have a customer who really enjoys readying Sci-fi, we might want to recommend other science fiction books to them, but not necessarily biographies.  Spark MLlib supports Collaborative Filtering, and it works by filling in something known as the user-item matrix.  So we can think of users as customers and items as books.  In this example below, we have a customer who likes item one and two and item four.  User number two, or customer number two, also likes item two and also likes item three.  Now, we’ll notice that user four has something in common with both user one and user three.  That means we probably want to recommend item two to user four.  This is an example of collaborative filtering.  This is the type of recommendation system that Spark MLlib supports.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">+-----+-----+-----+-----+-----+</span><br><span class="line">|     |Item1|Item2|Item3|Item4|</span><br><span class="line">+-----+-----+-----+-----+-----+</span><br><span class="line">|User1|  x  |  x  |     |  x  |</span><br><span class="line">|User1|     |  x  |  x  |     |</span><br><span class="line">|User1|     |     |     |  x  |</span><br><span class="line">|User1|  x  |  ?  |  x  |     |</span><br><span class="line">+-----+-----+-----+-----+-----+</span><br></pre></td></tr></table></figure>

<h2 id="Collaborative-Filtering"><a href="#Collaborative-Filtering" class="headerlink" title="Collaborative Filtering"></a>Collaborative Filtering</h2><p>Collaborative filtering follows the same patterns we’ve used repeatedly in this post.</p>
<p>First we start with preprocessing.  We’re going to use the alternating least squares method that’s provided by Spark MLlib, and, to use that, we just import the ALS code from pyspark.ml.recommendation package.  And then we build a DataFrame using user-item ratings.</p>
<p>When it comes to modeling, we create an ALS object and, when we do that, we have to specify the user, the item, and the rating columns in our data frames.  And then we train the model using fit and fit is part of the ALS project.  And then when it’s time to evaluate, we create predictions using the transform of the ALS model and we apply that to our test data.  We create a RegressionEvaluator object and we use the evaluate function of that RegressionEvaluator object to calculate the root mean squared error, and that’ll give us a measure of how well our collaborative filtering is making recommendations.</p>
<h1 id="Tips-for-Using-Spark-MLlib"><a href="#Tips-for-Using-Spark-MLlib" class="headerlink" title="Tips for Using Spark MLlib"></a>Tips for Using Spark MLlib</h1><p>Let’s review some tips for working with Spark MLlib.</p>
<p>There are three basic stages of building machine learning models.  There’s a pre-processing phase where we collect, reformat, and transform the data.  And once we have that data, we can build our models using a variety of machine learning algorithms.  And then we want to make sure we evaluate our data to assess the quality of the models we built.</p>
<p>With that framework in mind, let’s look at some tips to make each of these stages go smoothly. First, when we’re pre-processing, we want to first load our data into DataFrames.  If you’re working with text files, it helps to have headers or column names in the text file.  When you read a file, make sure you use the inferSchema = True option.  That’ll make sure that things like dates and numeric values get mapped to their appropriate data type.  Use the VectorAssembler to create feature vectors and the StringIndexer to map from strings to numeric indexes.</p>
<p>During the model building phase, make sure to split your data into training and test sets. We use the training data to fit our models and then the test data to apply transformations to create predictions.  When we’re done building the model, we want to validate them.  I recommend using the MLlib evaluators.  The two that we looked at were the MulticlassClassificationEvaluator and the RegressionEvaluator.  Just be sure to use the right one for the kind of algorithm you’re working with.  Also, be sure to experiment with multiple algorithms.  Once you’ve gone through the pre-processing phase, it’s very easy to test other algorithms so take advantage of that.  Also, vary hyperparameters for the algorithms you’re working with.  Sometimes you can get slightly better performance just by changing a hyperparameter.</p>
<p>Where do we go from here? Well first I’d recommend consulting the MLlib documentation.  It’s really high quality documentation and it provides details on the APIs and includes extensive examples.  When you’re ready to work with other data sets, look at the Kaggle website that has both machine learning data sets and articles about machine learning.  Now Spark is designed for working with big data so if you’re ready to work with machine learning at big data scales, consult the AWS data sets.  These are public data sets that are freely available from the AWS cloud service.  Spark and MLlib are both under active development. So as you go forward working with MLlib, be sure to check back at the Spark MLlib website for updates and new features.</p>
</div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="mailto:undefined">Zilan Huang</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="http://tedlsx.github.io/2019/08/20/Spark-for-Machine-Learning-AI/">http://tedlsx.github.io/2019/08/20/Spark-for-Machine-Learning-AI/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Big-Data/">Big Data    </a><a class="post-meta__tags" href="/tags/Data-Science/">Data Science    </a><a class="post-meta__tags" href="/tags/Data-Processing/">Data Processing    </a><a class="post-meta__tags" href="/tags/Machine-Learning/">Machine Learning    </a><a class="post-meta__tags" href="/tags/AI/">AI    </a><a class="post-meta__tags" href="/tags/Model/">Model    </a><a class="post-meta__tags" href="/tags/Query/">Query    </a></div><div class="post_share"><div class="social-share" data-image="/img/spark.jpeg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js@1.0.16/dist/css/share.min.css"><script src="https://cdn.jsdelivr.net/npm/social-share.js@1.0.16/dist/js/social-share.min.js"></script></div></div><div class="post-reward"><a class="reward-buttom"><i class="fa fa-qrcode"></i> Donate<div class="reward-main"><ul class="reward-all"><li class="reward-item"><img class="lozad post-qr-code__img" src="/img/wechat.jpeg"><div class="post-qr-code__desc">微信</div></li><li class="reward-item"><img class="lozad post-qr-code__img" src="/img/alipay.jpeg"><div class="post-qr-code__desc">支付寶</div></li></ul></div></a></div><nav class="pagination_post" id="pagination"><div class="next-post pull-full"><a href="/2019/08/19/Hadoop-Environment-Setup/"><img class="next_cover lozad" data-src="/img/hadoop.png" onerror="onerror=null;src='/img/404.jpg'"><div class="label">Next Post</div><div class="next_info"><span>Hadoop Environment Setup</span></div></a></div></nav><div class="relatedPosts"><div class="relatedPosts_headline"><i class="fa fa-fw fa-thumbs-up" aria-hidden="true"></i><span> Recommend</span></div><div class="relatedPosts_list"><div class="relatedPosts_item"><a href="/2019/08/19/Hadoop-Environment-Setup/" title="Hadoop Environment Setup"><img class="relatedPosts_cover lozad" data-src="/img/hadoop.png"><div class="relatedPosts_title">Hadoop Environment Setup</div></a></div></div><div class="clear_both"></div></div><hr><div id="post-comment"><div class="comment_headling"><i class="fa fa-comments fa-fw" aria-hidden="true"></i><span> Comment</span></div><div id="disqus_thread"></div><script>var unused = null;
var disqus_config = function () {
  this.page.url = 'http://tedlsx.github.io/2019/08/20/Spark-for-Machine-Learning-AI/';
  this.page.identifier = '2019/08/20/Spark-for-Machine-Learning-AI/';
  this.page.title = 'Spark for Machine Learning and AI';
}
var d = document, s = d.createElement('script');
s.src = "https://" + 'hoanjinan-otoko' +".disqus.com/embed.js";
s.setAttribute('data-timestamp', '' + +new Date());
(d.head || d.body).appendChild(s);</script></div></div></div><footer><div class="layout" id="footer"><div class="copyright">&copy;2019 By Zilan Huang</div><div class="framework-info"><span>Driven </span><a href="http://hexo.io"><span>Hexo</span></a><span class="footer-separator">|</span><span>Theme </span><a href="https://github.com/jerryc127/hexo-theme-butterfly"><span>Butterfly</span></a></div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><section class="rightside" id="rightside"><i class="fa fa-book" id="readmode" title="Read Mode"> </i><i class="fa fa-plus" id="font_plus" title="Increase font size"></i><i class="fa fa-minus" id="font_minus" title="Decrease font size"></i><a class="translate_chn_to_cht" id="translateLink" href="javascript:translatePage();" title="Traditional Chinese and Simplified Chinese Conversion">简</a><i class="fa fa-moon-o nightshift" id="nightshift" title="Dark Mode"></i></section><div id="post_bottom"><div id="post_bottom_items"><a id="to_comment" href="#post-comment"><i class="scroll_to_comment fa fa-comments"></i></a><i class="fa fa-list" id="mobile_toc"></i><div id="toc_mobile"><div class="toc_mobile_headline">Catalog</div><ol class="toc_mobile_items"><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#Introduction-to-The-Post"><span class="toc_mobile_items-number">1.</span> <span class="toc_mobile_items-text">Introduction to The Post</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#Introduction-to-Spark"><span class="toc_mobile_items-number">2.</span> <span class="toc_mobile_items-text">Introduction to Spark</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#Steps-in-Machine-Learning-Process"><span class="toc_mobile_items-number">3.</span> <span class="toc_mobile_items-text">Steps in Machine Learning Process</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#Creating-Spark-Session-and-Basic-Dataframe-Processing"><span class="toc_mobile_items-number">4.</span> <span class="toc_mobile_items-text">Creating Spark Session and Basic Dataframe Processing</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#Create-Spark-Session"><span class="toc_mobile_items-number">4.1.</span> <span class="toc_mobile_items-text">Create Spark Session</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#Basic-Dataframe-Processing"><span class="toc_mobile_items-number">4.2.</span> <span class="toc_mobile_items-text">Basic Dataframe Processing</span></a></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#Components-of-Spark-MLlib"><span class="toc_mobile_items-number">5.</span> <span class="toc_mobile_items-text">Components of Spark MLlib</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#Introduction-to-Preprocessing"><span class="toc_mobile_items-number">6.</span> <span class="toc_mobile_items-text">Introduction to Preprocessing</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#Numeric"><span class="toc_mobile_items-number">6.1.</span> <span class="toc_mobile_items-text">Numeric</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#Normalisation-MinMaxScaler"><span class="toc_mobile_items-number">6.1.1.</span> <span class="toc_mobile_items-text">Normalisation (MinMaxScaler)</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#Standardisation-StandardScaler"><span class="toc_mobile_items-number">6.1.2.</span> <span class="toc_mobile_items-text">Standardisation (StandardScaler)</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#Partition-Bucketiser"><span class="toc_mobile_items-number">6.1.3.</span> <span class="toc_mobile_items-text">Partition (Bucketiser)</span></a></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#Text"><span class="toc_mobile_items-number">6.2.</span> <span class="toc_mobile_items-text">Text</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#Tokenisation-Tokeniser"><span class="toc_mobile_items-number">6.2.1.</span> <span class="toc_mobile_items-text">Tokenisation (Tokeniser)</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#Term-Frequency-Inverse-Document-Frequency-TF-IDF-Hashing-TF"><span class="toc_mobile_items-number">6.2.2.</span> <span class="toc_mobile_items-text">Term Frequency Inverse Document Frequency (TF-IDF) - (Hashing TF)</span></a></li></ol></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#Introduction-to-Clustering"><span class="toc_mobile_items-number">7.</span> <span class="toc_mobile_items-text">Introduction to Clustering</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#K-means-Clustering"><span class="toc_mobile_items-number">7.1.</span> <span class="toc_mobile_items-text">K-means Clustering</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#Hierarchical-Clustering"><span class="toc_mobile_items-number">7.2.</span> <span class="toc_mobile_items-text">Hierarchical Clustering</span></a></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#Introduction-to-Classification"><span class="toc_mobile_items-number">8.</span> <span class="toc_mobile_items-text">Introduction to Classification</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#Preprocessing-The-Iris-Dataset"><span class="toc_mobile_items-number">8.1.</span> <span class="toc_mobile_items-text">Preprocessing The Iris Dataset</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#Naive-Bayes-Classification"><span class="toc_mobile_items-number">8.2.</span> <span class="toc_mobile_items-text">Naive Bayes Classification</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#Multilayer-Perceptron-Classification"><span class="toc_mobile_items-number">8.3.</span> <span class="toc_mobile_items-text">Multilayer Perceptron Classification</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#Decision-Trees-Classification"><span class="toc_mobile_items-number">8.4.</span> <span class="toc_mobile_items-text">Decision Trees Classification</span></a></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#Introduction-to-Regresssion"><span class="toc_mobile_items-number">9.</span> <span class="toc_mobile_items-text">Introduction to Regresssion</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#Pre-processing-The-Dataset"><span class="toc_mobile_items-number">9.1.</span> <span class="toc_mobile_items-text">Pre-processing The Dataset</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#Linear-Regression"><span class="toc_mobile_items-number">9.2.</span> <span class="toc_mobile_items-text">Linear Regression</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#Decision-Tree-Regression"><span class="toc_mobile_items-number">9.3.</span> <span class="toc_mobile_items-text">Decision Tree Regression</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#Gradient-boosted-Tree-Regression"><span class="toc_mobile_items-number">9.4.</span> <span class="toc_mobile_items-text">Gradient-boosted Tree Regression</span></a></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#Understand-Recommendation-Systems"><span class="toc_mobile_items-number">10.</span> <span class="toc_mobile_items-text">Understand Recommendation Systems</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#Collaborative-Filtering"><span class="toc_mobile_items-number">10.1.</span> <span class="toc_mobile_items-text">Collaborative Filtering</span></a></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#Tips-for-Using-Spark-MLlib"><span class="toc_mobile_items-number">11.</span> <span class="toc_mobile_items-text">Tips for Using Spark MLlib</span></a></li></ol></div></div></div><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/js-cookie@2/src/js.cookie.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script async src="/js/search/local-search.js"></script><script src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script src="/js/third-party/fireworks.js"></script><script src="/js/nightshift.js"></script><script id="ribbon" src="/js/third-party/canvas-ribbon.js" size="150" alpha="0.6" zindex="-1" data-click="false"></script><script id="ribbon" src="https://cdn.jsdelivr.net/gh/jerryc127/CDN@latest/js/piao.js"></script><script src="/js/activate-power-mode.js"></script><script>POWERMODE.colorful = true; // make power mode colorful
POWERMODE.shake = true; // turn off shake
document.body.addEventListener('input', POWERMODE);
</script><script src="/js/tw_cn.js"></script><script>translateInitilization()

</script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page@1.2.2/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/lozad/dist/lozad.min.js"></script><script>const observer = lozad(); // lazy loads elements with default selector as '.lozad'
observer.observe();</script><div class="search-dialog" id="local-search"><div class="search-dialog__title" id="local-search-title">Local search</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="Search for Posts"></div></div></div><hr><div id="local-search-results"><div id="local-hits"></div><div id="local-stats"><div class="local-search-stats__hr" id="hr"><span>Powered by</span> <a href="https://github.com/wzpan/hexo-generator-search" style="color:#49B1F5;">hexo-generator-search</a></div></div></div><span class="search-close-button"><i class="fa fa-times"></i></span></div><div class="search-mask"></div><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","model":{"jsonPath":"/live2dw/assets/shizuku.model.json"},"display":{"position":"right","width":150,"height":300,"hOffset":100,"vOffset":-10},"mobile":{"show":true},"log":false,"tagMode":false});</script></body></html>