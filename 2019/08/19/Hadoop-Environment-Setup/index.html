<!DOCTYPE html><html lang="en"><head><meta name="generator" content="Hexo 3.9.0"><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><title>Hadoop Environment Setup | hoanjinan_otoko</title><meta name="description" content="This post is going to help you completely configering Hadoop environment with Spark and other essential setups from scratch.  The post includes Operating System(Ubuntu), Hadoop, Spark, Jupyter, SSH Setup."><meta name="keywords" content="Setup,Environment,Installation,Configuration"><meta name="author" content="Zilan Huang"><meta name="copyright" content="Zilan Huang"><meta name="format-detection" content="telephone=no"><link rel="shortcut icon" href="/img/favicon.png"><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.8.1/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><meta http-equiv="x-dns-prefetch-control" content="on"><link rel="canonical" href="http://hoanjinan.github.io/2019/08/19/Hadoop-Environment-Setup/"><meta name="twitter:card" content="summary_large_image"><meta name="twitter:title" content="Hadoop Environment Setup"><meta name="twitter:description" content="This post is going to help you completely configering Hadoop environment with Spark and other essential setups from scratch.  The post includes Operating System(Ubuntu), Hadoop, Spark, Jupyter, SSH Setup."><meta name="twitter:image" content="http://hoanjinan.github.io/img/hadoop.png"><meta property="og:type" content="article"><meta property="og:title" content="Hadoop Environment Setup"><meta property="og:url" content="http://hoanjinan.github.io/2019/08/19/Hadoop-Environment-Setup/"><meta property="og:site_name" content="hoanjinan_otoko"><meta property="og:description" content="This post is going to help you completely configering Hadoop environment with Spark and other essential setups from scratch.  The post includes Operating System(Ubuntu), Hadoop, Spark, Jupyter, SSH Setup."><meta property="og:image" content="http://hoanjinan.github.io/img/hadoop.png"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="next" title="Hello World" href="http://hoanjinan.github.io/2019/08/16/hello-world/"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: {"defaultEncoding":1,"translateDelay":0,"cookieDomain":"https://xxx/","msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"简"},
  highlight_copy: 'true',
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  bookmark: {
    title: 'Bookmark',
    message_prev: 'Press',
    message_next: 'to bookmark this page'
  },
  runtime_unit: 'days'

  
}</script></head><body><canvas class="fireworks"></canvas><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div class="auto_open" id="sidebar"><div class="sidebar-toc"><div class="sidebar-toc__title">Catalog</div><div class="sidebar-toc__progress"><span class="progress-notice">You've read</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar"></div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Ubuntu-Installation"><span class="toc-number">1.</span> <span class="toc-text">Ubuntu Installation</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-Version-Ubuntu-Desktop-18-04-2-LTS"><span class="toc-number">1.0.1.</span> <span class="toc-text">1. Version: Ubuntu Desktop 18.04.2 LTS</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-Installation-Tutorial-Install-Ubuntu-Desktop"><span class="toc-number">1.0.2.</span> <span class="toc-text">2. Installation Tutorial: Install Ubuntu Desktop</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-Disable-Auto-Update"><span class="toc-number">1.0.3.</span> <span class="toc-text">3. Disable Auto Update</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-Disable-Auto-Shut-Down-and-Sleep"><span class="toc-number">1.0.4.</span> <span class="toc-text">4. Disable Auto Shut Down and Sleep</span></a></li></ol></li></ol><li class="toc-item toc-level-1"><a class="toc-link" href="#Hadoop-Environment-Setup"><span class="toc-number">2.</span> <span class="toc-text">Hadoop Environment Setup</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Pre-installation-Setup"><span class="toc-number">2.1.</span> <span class="toc-text">Pre-installation Setup</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-Checking-Hostname"><span class="toc-number">2.1.1.</span> <span class="toc-text">1. Checking Hostname</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-Checking-Current-IP-Address"><span class="toc-number">2.1.2.</span> <span class="toc-text">2. Checking Current IP Address</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-Install-vim"><span class="toc-number">2.1.3.</span> <span class="toc-text">3. Install vim</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-Add-IP-Addresses"><span class="toc-number">2.1.4.</span> <span class="toc-text">4. Add IP Addresses</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Java-JDK-Installation"><span class="toc-number">2.2.</span> <span class="toc-text">Java JDK Installation</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-Version-Java-SE-Development-Kit-8u221-Requires-Registration"><span class="toc-number">2.2.1.</span> <span class="toc-text">1. Version: Java SE Development Kit 8u221 (Requires Registration)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-Extract-the-Files-to-usr-lib-jvm"><span class="toc-number">2.2.2.</span> <span class="toc-text">2. Extract the Files to /usr/lib/jvm/</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-Add-Java’s-Path-into-PATH"><span class="toc-number">2.2.3.</span> <span class="toc-text">3. Add Java’s Path into $PATH</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-Check-Java-Version-and-Path"><span class="toc-number">2.2.4.</span> <span class="toc-text">4. Check Java Version and Path</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Setup-SSH"><span class="toc-number">2.3.</span> <span class="toc-text">Setup SSH</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Hadoop-Installation"><span class="toc-number">2.4.</span> <span class="toc-text">Hadoop Installation</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-Install-Hadoop"><span class="toc-number">2.4.1.</span> <span class="toc-text">1. Install Hadoop</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-Add-Hadoop’s-Path-into-PATH"><span class="toc-number">2.4.2.</span> <span class="toc-text">2. Add Hadoop’s Path into $PATH</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-Configure-Hadoop"><span class="toc-number">2.4.3.</span> <span class="toc-text">3. Configure Hadoop</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Spark-Environment-Setup"><span class="toc-number">3.</span> <span class="toc-text">Spark Environment Setup</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-Install-Spark"><span class="toc-number">3.0.1.</span> <span class="toc-text">1. Install Spark</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-Add-Pathes-into-PATH"><span class="toc-number">3.0.2.</span> <span class="toc-text">2. Add Pathes into $PATH</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-Configure-Spark"><span class="toc-number">3.0.3.</span> <span class="toc-text">3. Configure Spark</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-Checking-Spark-version"><span class="toc-number">3.0.4.</span> <span class="toc-text">4. Checking Spark version</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Setup-Public-Jupyter-Notebook"><span class="toc-number">4.</span> <span class="toc-text">Setup Public Jupyter Notebook</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Extras"><span class="toc-number">5.</span> <span class="toc-text">Extras</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Change-Machines’-Username"><span class="toc-number">5.1.</span> <span class="toc-text">Change Machines’ Username</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Docker-Suspended-Not-in-use"><span class="toc-number">5.2.</span> <span class="toc-text">Docker (Suspended - Not in use)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Useful-Commands"><span class="toc-number">5.3.</span> <span class="toc-text">Useful Commands</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-General-Commands"><span class="toc-number">5.3.1.</span> <span class="toc-text">1. General Commands</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-Resetting-PATH-In-case-if-the-PATH-is-overwritten-by-mistake"><span class="toc-number">5.3.2.</span> <span class="toc-text">2. Resetting $PATH (In case if the $PATH is overwritten by mistake)</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#References"><span class="toc-number">6.</span> <span class="toc-text">References</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-Hadoop"><span class="toc-number">6.0.1.</span> <span class="toc-text">1. Hadoop</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-Java-JDK"><span class="toc-number">6.0.2.</span> <span class="toc-text">2. Java JDK</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-Spark"><span class="toc-number">6.0.3.</span> <span class="toc-text">3. Spark</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-Jupyter-Notebook"><span class="toc-number">6.0.4.</span> <span class="toc-text">4. Jupyter Notebook</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-HDFS"><span class="toc-number">6.0.5.</span> <span class="toc-text">5. HDFS</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-Docker"><span class="toc-number">6.0.6.</span> <span class="toc-text">6. Docker</span></a></li></ol></li></div></div></div><div id="content-outer"><div id="top-container" style="background-image: url(/img/data_centre.jpg)"><div id="page-header"><span class="pull-left"> <a class="blog_title" id="site-name" href="/">hoanjinan_otoko</a></span><div class="open toggle-menu pull-right"><div class="menu-icon-first"></div><div class="menu-icon-second"></div><div class="menu-icon-third"></div></div><span class="pull-right menus"><div class="mobile_author_icon"><img class="lozad" src="/img/avatar.jpeg" onerror="onerror=null;src='/img/friend_404.gif'"><div class="mobile_author-info__description"></div></div><hr><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a><script>document.body.addEventListener('touchstart', function(){ });</script></div></span><span class="pull-right"></span></div><div id="post-info"><div id="post-title"><div class="posttitle">Hadoop Environment Setup</div></div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> Created 2019-08-19<span class="post-meta__separator">|</span><i class="fa fa-history" aria-hidden="true"></i> Updated 2019-08-19</time><span class="post-meta__separator mobile_hidden">|</span><span class="mobile_hidden"><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/Tutorial/">Tutorial</a><i class="fa fa-angle-right" aria-hidden="true"></i><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/Tutorial/Big-Data/">Big Data</a></span></div></div></div><div class="layout layout_post" id="content-inner">   <article id="post"><div class="article-container" id="post-content"><h1 id="Ubuntu-Installation"><a href="#Ubuntu-Installation" class="headerlink" title="Ubuntu Installation"></a>Ubuntu Installation</h1><h3 id="1-Version-Ubuntu-Desktop-18-04-2-LTS"><a href="#1-Version-Ubuntu-Desktop-18-04-2-LTS" class="headerlink" title="1. Version: Ubuntu Desktop 18.04.2 LTS"></a>1. Version: <a href="https://ubuntu.com/download/desktop" target="_blank" rel="noopener">Ubuntu Desktop 18.04.2 LTS</a></h3><h3 id="2-Installation-Tutorial-Install-Ubuntu-Desktop"><a href="#2-Installation-Tutorial-Install-Ubuntu-Desktop" class="headerlink" title="2. Installation Tutorial: Install Ubuntu Desktop"></a>2. Installation Tutorial: <a href="https://tutorials.ubuntu.com/tutorial/tutorial-install-ubuntu-desktop#0" target="_blank" rel="noopener">Install Ubuntu Desktop</a></h3><h3 id="3-Disable-Auto-Update"><a href="#3-Disable-Auto-Update" class="headerlink" title="3. Disable Auto Update"></a>3. Disable Auto Update</h3><h3 id="4-Disable-Auto-Shut-Down-and-Sleep"><a href="#4-Disable-Auto-Shut-Down-and-Sleep" class="headerlink" title="4. Disable Auto Shut Down and Sleep"></a>4. Disable Auto Shut Down and Sleep</h3><p><strong><em>Notice: In log in details session, please set your computer’s name as master/slave1/slave2/slave3 and set username as hadoop across all machines.</em></strong></p>
<h1 id="Hadoop-Environment-Setup"><a href="#Hadoop-Environment-Setup" class="headerlink" title="Hadoop Environment Setup"></a>Hadoop Environment Setup</h1><h2 id="Pre-installation-Setup"><a href="#Pre-installation-Setup" class="headerlink" title="Pre-installation Setup"></a>Pre-installation Setup</h2><h3 id="1-Checking-Hostname"><a href="#1-Checking-Hostname" class="headerlink" title="1. Checking Hostname"></a>1. Checking Hostname</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hadoop@slave1:~$ hostname</span><br><span class="line">slave1</span><br></pre></td></tr></table></figure>

<h3 id="2-Checking-Current-IP-Address"><a href="#2-Checking-Current-IP-Address" class="headerlink" title="2. Checking Current IP Address"></a>2. Checking Current IP Address</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hadoop@slave1:~$ hostname -I</span><br><span class="line">10.22.16.84 172.17.0.1</span><br></pre></td></tr></table></figure>

<h3 id="3-Install-vim"><a href="#3-Install-vim" class="headerlink" title="3. Install vim"></a>3. Install vim</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hadoop@slave1:~$ <span class="built_in">cd</span> /</span><br><span class="line">hadoop@slave1:/$ <span class="built_in">cd</span> etc</span><br><span class="line">hadoop@slave1:/etc$ sudo apt install vim</span><br></pre></td></tr></table></figure>

<h3 id="4-Add-IP-Addresses"><a href="#4-Add-IP-Addresses" class="headerlink" title="4. Add IP Addresses"></a>4. Add IP Addresses</h3><p>Insert the information from the table below into /etc/hosts file.<br>| IP Addresses | Hostnames |<br>| ———— | ——— |<br>| 10.22.17.39 | master |<br>| 10.22.16.84 | slave1 |<br>| 10.22.17.150 | slave2 |<br>| 10.22.17.79 | slave3 |</p>
<p>Command to open and insert information:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop@slave1:/etc$ sudo vim hosts</span><br></pre></td></tr></table></figure>

<p>Check if connections to other machines can be established:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop@slave1:/etc$ ping master</span><br></pre></td></tr></table></figure>

<h2 id="Java-JDK-Installation"><a href="#Java-JDK-Installation" class="headerlink" title="Java JDK Installation"></a>Java JDK Installation</h2><h3 id="1-Version-Java-SE-Development-Kit-8u221-Requires-Registration"><a href="#1-Version-Java-SE-Development-Kit-8u221-Requires-Registration" class="headerlink" title="1. Version: Java SE Development Kit 8u221 (Requires Registration)"></a>1. Version: <a href="https://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html" target="_blank" rel="noopener">Java SE Development Kit 8u221</a> (Requires Registration)</h3><h3 id="2-Extract-the-Files-to-usr-lib-jvm"><a href="#2-Extract-the-Files-to-usr-lib-jvm" class="headerlink" title="2. Extract the Files to /usr/lib/jvm/"></a>2. Extract the Files to /usr/lib/jvm/</h3><h3 id="3-Add-Java’s-Path-into-PATH"><a href="#3-Add-Java’s-Path-into-PATH" class="headerlink" title="3. Add Java’s Path into $PATH"></a>3. Add Java’s Path into $PATH</h3><p>Open /etc/profile file to write the Java path into:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hadoop@slave1:~$ <span class="built_in">cd</span> /etc</span><br><span class="line">hadoop@slave1:~$ sudo vim profile</span><br></pre></td></tr></table></figure>

<p>Insert the following code into the file:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> JAVA_HOME=/usr/lib/jvm/jdk1.8.0_211</span><br><span class="line"><span class="built_in">export</span> CLASSPATH=.:<span class="variable">$CLASSPATH</span>:<span class="variable">$JAVA_HOME</span>/lib</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$JAVA_HOME</span>/bin</span><br></pre></td></tr></table></figure>

<p>Source the file to apply the changes:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop@slave1:~$ <span class="built_in">source</span> profile</span><br></pre></td></tr></table></figure>

<p><strong><em>Notice: You may need to restart your computer to apply the changes permanently.</em></strong></p>
<h3 id="4-Check-Java-Version-and-Path"><a href="#4-Check-Java-Version-and-Path" class="headerlink" title="4. Check Java Version and Path"></a>4. Check Java Version and Path</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">hadoop@slave1:~$ java -version</span><br><span class="line">java version <span class="string">"1.8.0_211"</span></span><br><span class="line">Java(TM) SE Runtime Environment (build 1.8.0_211-b12)</span><br><span class="line">Java HotSpot(TM) 64-Bit Server VM (build 25.211-b12, mixed mode)</span><br><span class="line">hadoop@slave1:~$ <span class="built_in">which</span> java</span><br><span class="line">/usr/lib/jvm/jdk1.8.0_211/bin/java</span><br></pre></td></tr></table></figure>

<h2 id="Setup-SSH"><a href="#Setup-SSH" class="headerlink" title="Setup SSH"></a>Setup SSH</h2><p>Setting up this to allow the machines to connect each other without entering passwords.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Installing SSH</span></span><br><span class="line">hadoop@slave1:~$ sudo apt-get install openssh-server</span><br><span class="line"></span><br><span class="line"><span class="comment">#Generate a SSH key</span></span><br><span class="line">hadoop@slave1:~$ ssh-keygen -t rsa</span><br><span class="line">hadoop@slave1:~$ <span class="built_in">cd</span> .ssh/</span><br><span class="line"></span><br><span class="line"><span class="comment">#Copy key into authorized_keys file</span></span><br><span class="line">hadoop@slave1:~/.ssh/$ cat id_rsa.pub &gt;&gt; authorized_keys</span><br><span class="line"></span><br><span class="line"><span class="comment">#To set the file that the owner can read and write on it</span></span><br><span class="line">hadoop@slave1:~/.ssh/$ chmod 0600 authorized_keys</span><br><span class="line"></span><br><span class="line"><span class="comment">#Configer settings on sshd_config file</span></span><br><span class="line">hadoop@slave1:~/.ssh/$ sudo vim /etc/ssh/sshd_config</span><br></pre></td></tr></table></figure>

<p>Type these lines in the end of the sshd_config file:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">RSAAuthentication yes</span><br><span class="line">PubkeyAuthentication yes</span><br><span class="line">AuthorizedKeysFile      %h/.ssh/authorized_keys</span><br></pre></td></tr></table></figure>

<p>Restarting the SSH service and copy its ssh id to other machines:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hadoop@slave1:~/.ssh/$ service ssh restart</span><br><span class="line">hadoop@slave1:~/.ssh/$ ssh-copy-id master@master</span><br><span class="line">hadoop@slave1:~/.ssh/$ ssh <span class="string">'master@master'</span></span><br></pre></td></tr></table></figure>

<h2 id="Hadoop-Installation"><a href="#Hadoop-Installation" class="headerlink" title="Hadoop Installation"></a>Hadoop Installation</h2><h3 id="1-Install-Hadoop"><a href="#1-Install-Hadoop" class="headerlink" title="1. Install Hadoop"></a>1. Install Hadoop</h3><ul>
<li>Version: <a href="https://www.apache.org/dyn/closer.cgi/hadoop/common/hadoop-3.1.2/hadoop-3.1.2.tar.gz" target="_blank" rel="noopener">Hadoop 3.1.2 (Binary)</a></li>
<li>Move Hadoop folder to /usr/ folder</li>
<li>Change folder name into hadoop</li>
<li>Make tmp folder inside of the hadoop folder</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">hadoop@slave1:/$ sudo mv hadoop-3.1.2/ /usr/</span><br><span class="line">hadoop@slave1:/$ <span class="built_in">cd</span> usr/</span><br><span class="line">hadoop@slave1:/usr$ sudo mv hadoop-3.1.2/ hadoop</span><br><span class="line"></span><br><span class="line"><span class="comment">#This line is going to give the permission to the user</span></span><br><span class="line">hadoop@slave1:/usr$ chown -R hadoop:slave1 hadoop/</span><br><span class="line">hadoop@slave1:/usr$ <span class="built_in">cd</span> hadoop/</span><br><span class="line">hadoop@slave1:/usr/hadoop$ mkdir tmp</span><br></pre></td></tr></table></figure>

<h3 id="2-Add-Hadoop’s-Path-into-PATH"><a href="#2-Add-Hadoop’s-Path-into-PATH" class="headerlink" title="2. Add Hadoop’s Path into $PATH"></a>2. Add Hadoop’s Path into $PATH</h3><p>Open /etc/profile file to write the Hadoop path into:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hadoop@slave1:~$ <span class="built_in">cd</span> /etc</span><br><span class="line">hadoop@slave1:~$ sudo vim profile</span><br></pre></td></tr></table></figure>

<p>Insert the following code into the file:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> HADOOP_HOME=/usr/hadoop</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$HADOOP_HOME</span>/bin:<span class="variable">$HADOOP_HOME</span>/sbin</span><br></pre></td></tr></table></figure>

<p>Source the file to apply the changes:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop@slave1:~$ <span class="built_in">source</span> profile</span><br></pre></td></tr></table></figure>

<p><strong><em>Notice: You may need to restart your computer to apply the changes permanently.</em></strong></p>
<h3 id="3-Configure-Hadoop"><a href="#3-Configure-Hadoop" class="headerlink" title="3. Configure Hadoop"></a>3. Configure Hadoop</h3><p>Change configeration settings in 5 following files:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Finding the paths on each file</span></span><br><span class="line">hadoop@slave1:/usr$ find hadoop -name hadoop-env.sh</span><br><span class="line">hadoop@slave1:/usr$ find hadoop -name core-site.xml</span><br><span class="line">hadoop@slave1:/usr$ find hadoop -name hdfs-site.xml</span><br><span class="line">hadoop@slave1:/usr$ find hadoop -name mapred-site.xml</span><br><span class="line">hadoop@slave1:/usr$ find hadoop -name yarn-site.xml</span><br></pre></td></tr></table></figure>

<p>5 paths:</p>
<ul>
<li>hadoop-env.sh - hadoop/etc/hadoop/hadoop-env.sh</li>
<li>core-site.xml - hadoop/etc/hadoop/core-site.xml</li>
<li>hdfs-site.xml - hadoop/etc/hadoop/hdfs-site.xml</li>
<li>mapred-site.xml - hadoop/etc/hadoop/mapred-site.xml</li>
<li>yarn-site.xml - hadoop/etc/hadoop/yarn-site.xml</li>
</ul>
<p>Configure <strong>hadoop_env.sh</strong>:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> JAVA_HOME=/usr/lib/jvm/jdk1.8.0_211</span><br></pre></td></tr></table></figure>

<p>Configure <strong>core-site.xml</strong>:</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/usr/hadoop/tmp<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">description</span>&gt;</span>A base for other temporary directories.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://master:9000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>Configure <strong>hdfs-site.xml</strong>:</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.premissions<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>Configure <strong>mapred-site.xml</strong>:</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>Configure <strong>yarn-site.xml</strong>:</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.resource.memory-mb<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>12288<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.env-whitelist<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>master<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.vmem-check-enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>The following command is going to insert the name for all workers in lines:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop@slave1:/usr/hadoop/etc/hadoop$ vim workers</span><br></pre></td></tr></table></figure>

<p>Here is the content in workers file:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">master</span><br><span class="line">slave1</span><br><span class="line">slave2</span><br><span class="line">slave3</span><br></pre></td></tr></table></figure>

<h1 id="Spark-Environment-Setup"><a href="#Spark-Environment-Setup" class="headerlink" title="Spark Environment Setup"></a>Spark Environment Setup</h1><h3 id="1-Install-Spark"><a href="#1-Install-Spark" class="headerlink" title="1. Install Spark"></a>1. Install Spark</h3><ul>
<li>Version: <a href="https://spark.apache.org/downloads.html" target="_blank" rel="noopener">Spark 2.4.3 (Binary)</a></li>
<li>Move Spark folder to /usr/hadoop/ folder</li>
<li>Change folder name into spark</li>
</ul>
<h3 id="2-Add-Pathes-into-PATH"><a href="#2-Add-Pathes-into-PATH" class="headerlink" title="2. Add Pathes into $PATH"></a>2. Add Pathes into $PATH</h3><p>Open the .bashrc file:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop@master:~$ vim .bashrc</span><br></pre></td></tr></table></figure>

<p>In .bashrc file, insert the following lines:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> HADOOP_HOME=/usr/hadoop</span><br><span class="line"><span class="built_in">export</span> HADOOP_INSTALL=<span class="variable">$HADOOP_HOME</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_MAPRED_HOME=<span class="variable">$HADOOP_HOME</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_COMMON_HOME=<span class="variable">$HADOOP_HOME</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_HDFS_HOME=<span class="variable">$HADOOP_HOME</span></span><br><span class="line"><span class="built_in">export</span> YARN_HOME=<span class="variable">$HADOOP_HOME</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_COMMON_LIB_NATIVE_DIR=<span class="variable">$HADOOP_HOME</span>/lib/native</span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> SPARK_HOME=/usr/hadoop/spark</span><br><span class="line"><span class="built_in">export</span> PYTHONPATH=<span class="variable">$SPARK_HOME</span>/python:<span class="variable">$PYTHONPATH</span></span><br><span class="line"><span class="built_in">export</span> PYSPARK_DRIVER_PYTHON=<span class="string">"jupyter"</span></span><br><span class="line"><span class="built_in">export</span> PYSPARK_DRIVER_PYTHON_OPTS=<span class="string">"notebook"</span></span><br><span class="line"><span class="built_in">export</span> PYSPARK_PYTHON=python3</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$SPARK_HOME</span>/bin:~/.<span class="built_in">local</span>/bin:<span class="variable">$SPARK_HOME</span></span><br></pre></td></tr></table></figure>

<p>Source the file to apply the changes:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop@master:~$ <span class="built_in">source</span> .bashrc</span><br></pre></td></tr></table></figure>

<p><strong><em>Notice: You may need to restart your computer to apply the changes permanently.</em></strong></p>
<h3 id="3-Configure-Spark"><a href="#3-Configure-Spark" class="headerlink" title="3. Configure Spark"></a>3. Configure Spark</h3><p>Configure the spark-defaults.conf file:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Change the template into actual file</span></span><br><span class="line">hadoop@master:/usr/hadoop/spark$ mv /conf/spark-defaults.conf.template /conf/spark-defaults.conf</span><br><span class="line">hadoop@master:/usr/hadoop/spark$ mv /conf/spark-env.template /conf/spark-env.sh</span><br><span class="line"></span><br><span class="line"><span class="comment">#Open and write file</span></span><br><span class="line">hadoop@master:/usr/hadoop$ vim spark/conf/spark-defaults.conf</span><br><span class="line"></span><br><span class="line"><span class="comment">#Contents should be put into the file</span></span><br><span class="line">spark.master                     yarn</span><br><span class="line">spark.eventLog.enabled           <span class="literal">true</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#Create the log directory in HDFS</span></span><br><span class="line">hadoop@master:/usr/hadoop$ hdfs dfs -mkdir /spark-logs</span><br></pre></td></tr></table></figure>

<h3 id="4-Checking-Spark-version"><a href="#4-Checking-Spark-version" class="headerlink" title="4. Checking Spark version"></a>4. Checking Spark version</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop@master:/usr/hadoop$ spark-shell –-version</span><br></pre></td></tr></table></figure>

<h1 id="Setup-Public-Jupyter-Notebook"><a href="#Setup-Public-Jupyter-Notebook" class="headerlink" title="Setup Public Jupyter Notebook"></a>Setup Public Jupyter Notebook</h1><p>After the installation of jupyter:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hadoop@master:~$ jupyter notebook --generate-config</span><br><span class="line">hadoop@master:~$ <span class="built_in">cd</span> .jupyter/</span><br><span class="line">hadoop@master:~/.jupyter/$ vim jupyter_notebook_config.py</span><br></pre></td></tr></table></figure>

<p>Uncomment lines and adjust some values:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">c.NotebookApp.ip = <span class="string">'master'</span></span><br><span class="line">c.NotebookApp.port = 9999</span><br><span class="line">c.NotebookApp.allow_password_change = True</span><br></pre></td></tr></table></figure>

<p><strong><em>Notice: After the first change of the password and login please set allow_password_change into False or comment it out.</em></strong></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">c.NotebookApp.allow_password_change = False</span><br></pre></td></tr></table></figure>

<h1 id="Extras"><a href="#Extras" class="headerlink" title="Extras"></a>Extras</h1><h2 id="Change-Machines’-Username"><a href="#Change-Machines’-Username" class="headerlink" title="Change Machines’ Username"></a>Change Machines’ Username</h2><p>The username should be all the same in different machines because when hadoop connects to other machines, it uses its username as default username for the other machines to connect each other.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Here should be the format for username@hostname on each machine</span></span><br><span class="line">hadoop@master</span><br><span class="line">hadoop@slave1</span><br><span class="line">hadoop@slave2</span><br><span class="line">hadoop@slave3</span><br></pre></td></tr></table></figure>

<p>If the username has been set wrong by mistake when installing the system, it needs changing by using the following commands:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hadoop@slave1:~$ sudo passwd root</span><br><span class="line">hadoop@slave1:~$ su -</span><br><span class="line">root@slave1:~\<span class="comment"># usermod -l hadoop -d /home/hadoop -m slave1</span></span><br></pre></td></tr></table></figure>

<p><strong><em>Notice: These command can only run after logging into other user.  So, please create a new user and then logout the purpose user and login into the new user to type these command to change the purpose user’s username by typing the commands above to the new user’s terminal.</em></strong></p>
<h2 id="Docker-Suspended-Not-in-use"><a href="#Docker-Suspended-Not-in-use" class="headerlink" title="Docker (Suspended - Not in use)"></a>Docker (<strong>Suspended</strong> - Not in use)</h2><p><a href="https://phoenixnap.com/kb/how-to-install-docker-on-ubuntu-18-04" target="_blank" rel="noopener">Guide to Install Docker</a></p>
<p><a href="https://hub.docker.com/signup" target="_blank" rel="noopener">Sign Up Docker</a></p>
<p>Login Docker:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hadoop@slave1:~$ sudo docker login</span><br><span class="line">hadoop@slave1:~$ mkdir images</span><br></pre></td></tr></table></figure>

<p><a href="https://hub.docker.com/r/sequenceiq/hadoop-docker/" target="_blank" rel="noopener">Guide to Use Hadoop Image</a></p>
<p>Pull -&gt; Run</p>
<h2 id="Useful-Commands"><a href="#Useful-Commands" class="headerlink" title="Useful Commands"></a>Useful Commands</h2><h3 id="1-General-Commands"><a href="#1-General-Commands" class="headerlink" title="1. General Commands"></a>1. General Commands</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Format the namenode - ONLY RUN ONCE</span></span><br><span class="line">hadoop@master:~$ hadoop namenode -format</span><br><span class="line"></span><br><span class="line"><span class="comment">#Start Service</span></span><br><span class="line">hadoop@master:~$ start-all.sh</span><br><span class="line"></span><br><span class="line"><span class="comment">#Stop Service</span></span><br><span class="line">hadoop@master:~$ stop-all.sh</span><br><span class="line"></span><br><span class="line"><span class="comment">#Get hdfs Report</span></span><br><span class="line">hadoop@master:~$ hdfs dfsadmin -report</span><br><span class="line"></span><br><span class="line"><span class="comment">#Copy Files to Remote Computer</span></span><br><span class="line">hadoop@slave1:~$ scp -r &lt;folder_name&gt; &lt;remote_username&gt;@&lt;remote_hostname&gt;:&lt;remote_path&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment">#Change Permission for Remote Computer</span></span><br><span class="line">hadoop@slave1:~$ chown -R &lt;remote_username&gt;:&lt;remote_hostname&gt; &lt;folder_name&gt;</span><br></pre></td></tr></table></figure>

<h3 id="2-Resetting-PATH-In-case-if-the-PATH-is-overwritten-by-mistake"><a href="#2-Resetting-PATH-In-case-if-the-PATH-is-overwritten-by-mistake" class="headerlink" title="2. Resetting $PATH (In case if the $PATH is overwritten by mistake)"></a>2. Resetting $PATH (In case if the $PATH is overwritten by mistake)</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> PATH=<span class="string">"/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:"</span></span><br><span class="line">hadoop@slave1:/$ <span class="built_in">source</span> environment</span><br></pre></td></tr></table></figure>

<h1 id="References"><a href="#References" class="headerlink" title="References"></a>References</h1><h3 id="1-Hadoop"><a href="#1-Hadoop" class="headerlink" title="1. Hadoop"></a>1. Hadoop</h3><p><a href="https://www.tutorialspoint.com/hadoop/hadoop_enviornment_setup.htm" target="_blank" rel="noopener">Hadoop Environment Configeration</a></p>
<p><a href="https://www.cnblogs.com/lanxuezaipiao/p/3525554.html" target="_blank" rel="noopener">一步步教你Hadoop多节点集群安装配置</a></p>
<p><a href="https://chaoge123456.github.io/Hadoop分布式集群搭建.html/" target="_blank" rel="noopener">Hadoop分布式集群搭建</a></p>
<p><a href="https://blog.csdn.net/zolalad/article/details/11470449" target="_blank" rel="noopener">Hadoop系统完全分布式集群搭建方法</a></p>
<h3 id="2-Java-JDK"><a href="#2-Java-JDK" class="headerlink" title="2. Java JDK"></a>2. Java JDK</h3><p><a href="https://stackoverflow.com/questions/14788345/how-to-install-the-jdk-on-ubuntu-linux" target="_blank" rel="noopener">How to install the JDK on Ubuntu Linux (OpenJDK)</a></p>
<p><a href="https://www.baeldung.com/oracle-jdk-vs-openjdk" target="_blank" rel="noopener">Differences between OpenJDK and Oracle JDK</a></p>
<h3 id="3-Spark"><a href="#3-Spark" class="headerlink" title="3. Spark"></a>3. Spark</h3><p><a href="https://opensource.com/article/18/11/pyspark-jupyter-notebook" target="_blank" rel="noopener">How to set up PySpark for your Jupyter notebook</a></p>
<p><a href="http://www.techguru.my/programming/install-spark-2-3-x-on-yarn-with-hadoop-3-x/" target="_blank" rel="noopener">Install Spark 2.3.x on YARN with Hadoop 3.x</a></p>
<p><a href="https://spark.apache.org/docs/latest/rdd-programming-guide.html" target="_blank" rel="noopener">RDD Programming Guide</a></p>
<h3 id="4-Jupyter-Notebook"><a href="#4-Jupyter-Notebook" class="headerlink" title="4. Jupyter Notebook"></a>4. Jupyter Notebook</h3><p><a href="https://jupyter-notebook.readthedocs.io/en/stable/public_server.html" target="_blank" rel="noopener">Tutorial on setting up public jupyter notebook</a></p>
<h3 id="5-HDFS"><a href="#5-HDFS" class="headerlink" title="5. HDFS"></a>5. HDFS</h3><p><a href="http://fibrevillage.com/storage/630-using-hdfs-command-line-to-manage-files-and-directories-on-hadoop" target="_blank" rel="noopener">Using hdfs command line to manage files and directories on Hadoop</a></p>
<h3 id="6-Docker"><a href="#6-Docker" class="headerlink" title="6. Docker"></a>6. Docker</h3><p><a href="https://phoenixnap.com/kb/how-to-install-docker-on-ubuntu-18-04" target="_blank" rel="noopener">How To Install Docker On Ubuntu</a></p>
</div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="mailto:undefined">Zilan Huang</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="http://hoanjinan.github.io/2019/08/19/Hadoop-Environment-Setup/">http://hoanjinan.github.io/2019/08/19/Hadoop-Environment-Setup/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Setup/">Setup    </a><a class="post-meta__tags" href="/tags/Environment/">Environment    </a><a class="post-meta__tags" href="/tags/Installation/">Installation    </a><a class="post-meta__tags" href="/tags/Configuration/">Configuration    </a></div><div class="post_share"><div class="social-share" data-image="/img/hadoop.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js@1.0.16/dist/css/share.min.css"><script src="https://cdn.jsdelivr.net/npm/social-share.js@1.0.16/dist/js/social-share.min.js"></script></div></div><div class="post-reward"><a class="reward-buttom"><i class="fa fa-qrcode"></i> Donate<div class="reward-main"><ul class="reward-all"><li class="reward-item"><img class="lozad post-qr-code__img" src="/img/wechat.jpg"><div class="post-qr-code__desc">微信</div></li><li class="reward-item"><img class="lozad post-qr-code__img" src="/img/alipay.jpg"><div class="post-qr-code__desc">支付寶</div></li></ul></div></a></div><nav class="pagination_post" id="pagination"><div class="next-post pull-full"><a href="/2019/08/16/hello-world/"><img class="next_cover lozad" data-src="https://cdn.jsdelivr.net/gh/jerryc127/CDN@latest/cover/default_bg.png" onerror="onerror=null;src='/img/404.jpg'"><div class="label">Next Post</div><div class="next_info"><span>Hello World</span></div></a></div></nav></div></div><footer><div class="layout" id="footer"><div class="copyright">&copy;2019 By Zilan Huang</div><div class="framework-info"><span>Driven </span><a href="http://hexo.io"><span>Hexo</span></a><span class="footer-separator">|</span><span>Theme </span><a href="https://github.com/jerryc127/hexo-theme-butterfly"><span>Butterfly</span></a></div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><section class="rightside" id="rightside"><i class="fa fa-book" id="readmode" title="Read Mode"> </i><i class="fa fa-plus" id="font_plus" title="Increase font size"></i><i class="fa fa-minus" id="font_minus" title="Decrease font size"></i><a class="translate_chn_to_cht" id="translateLink" href="javascript:translatePage();" title="Traditional Chinese and Simplified Chinese Conversion">简</a><i class="fa fa-moon-o nightshift" id="nightshift" title="Dark Mode"></i></section><div id="post_bottom"><div id="post_bottom_items"><a id="to_comment" href="#post-comment"><i class="scroll_to_comment fa fa-comments"></i></a><i class="fa fa-list" id="mobile_toc"></i><div id="toc_mobile"><div class="toc_mobile_headline">Catalog</div><ol class="toc_mobile_items"><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#Ubuntu-Installation"><span class="toc_mobile_items-number">1.</span> <span class="toc_mobile_items-text">Ubuntu Installation</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#1-Version-Ubuntu-Desktop-18-04-2-LTS"><span class="toc_mobile_items-number">1.0.1.</span> <span class="toc_mobile_items-text">1. Version: Ubuntu Desktop 18.04.2 LTS</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#2-Installation-Tutorial-Install-Ubuntu-Desktop"><span class="toc_mobile_items-number">1.0.2.</span> <span class="toc_mobile_items-text">2. Installation Tutorial: Install Ubuntu Desktop</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#3-Disable-Auto-Update"><span class="toc_mobile_items-number">1.0.3.</span> <span class="toc_mobile_items-text">3. Disable Auto Update</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#4-Disable-Auto-Shut-Down-and-Sleep"><span class="toc_mobile_items-number">1.0.4.</span> <span class="toc_mobile_items-text">4. Disable Auto Shut Down and Sleep</span></a></li></ol></li></ol><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#Hadoop-Environment-Setup"><span class="toc_mobile_items-number">2.</span> <span class="toc_mobile_items-text">Hadoop Environment Setup</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#Pre-installation-Setup"><span class="toc_mobile_items-number">2.1.</span> <span class="toc_mobile_items-text">Pre-installation Setup</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#1-Checking-Hostname"><span class="toc_mobile_items-number">2.1.1.</span> <span class="toc_mobile_items-text">1. Checking Hostname</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#2-Checking-Current-IP-Address"><span class="toc_mobile_items-number">2.1.2.</span> <span class="toc_mobile_items-text">2. Checking Current IP Address</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#3-Install-vim"><span class="toc_mobile_items-number">2.1.3.</span> <span class="toc_mobile_items-text">3. Install vim</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#4-Add-IP-Addresses"><span class="toc_mobile_items-number">2.1.4.</span> <span class="toc_mobile_items-text">4. Add IP Addresses</span></a></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#Java-JDK-Installation"><span class="toc_mobile_items-number">2.2.</span> <span class="toc_mobile_items-text">Java JDK Installation</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#1-Version-Java-SE-Development-Kit-8u221-Requires-Registration"><span class="toc_mobile_items-number">2.2.1.</span> <span class="toc_mobile_items-text">1. Version: Java SE Development Kit 8u221 (Requires Registration)</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#2-Extract-the-Files-to-usr-lib-jvm"><span class="toc_mobile_items-number">2.2.2.</span> <span class="toc_mobile_items-text">2. Extract the Files to /usr/lib/jvm/</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#3-Add-Java’s-Path-into-PATH"><span class="toc_mobile_items-number">2.2.3.</span> <span class="toc_mobile_items-text">3. Add Java’s Path into $PATH</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#4-Check-Java-Version-and-Path"><span class="toc_mobile_items-number">2.2.4.</span> <span class="toc_mobile_items-text">4. Check Java Version and Path</span></a></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#Setup-SSH"><span class="toc_mobile_items-number">2.3.</span> <span class="toc_mobile_items-text">Setup SSH</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#Hadoop-Installation"><span class="toc_mobile_items-number">2.4.</span> <span class="toc_mobile_items-text">Hadoop Installation</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#1-Install-Hadoop"><span class="toc_mobile_items-number">2.4.1.</span> <span class="toc_mobile_items-text">1. Install Hadoop</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#2-Add-Hadoop’s-Path-into-PATH"><span class="toc_mobile_items-number">2.4.2.</span> <span class="toc_mobile_items-text">2. Add Hadoop’s Path into $PATH</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#3-Configure-Hadoop"><span class="toc_mobile_items-number">2.4.3.</span> <span class="toc_mobile_items-text">3. Configure Hadoop</span></a></li></ol></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#Spark-Environment-Setup"><span class="toc_mobile_items-number">3.</span> <span class="toc_mobile_items-text">Spark Environment Setup</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#1-Install-Spark"><span class="toc_mobile_items-number">3.0.1.</span> <span class="toc_mobile_items-text">1. Install Spark</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#2-Add-Pathes-into-PATH"><span class="toc_mobile_items-number">3.0.2.</span> <span class="toc_mobile_items-text">2. Add Pathes into $PATH</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#3-Configure-Spark"><span class="toc_mobile_items-number">3.0.3.</span> <span class="toc_mobile_items-text">3. Configure Spark</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#4-Checking-Spark-version"><span class="toc_mobile_items-number">3.0.4.</span> <span class="toc_mobile_items-text">4. Checking Spark version</span></a></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#Setup-Public-Jupyter-Notebook"><span class="toc_mobile_items-number">4.</span> <span class="toc_mobile_items-text">Setup Public Jupyter Notebook</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#Extras"><span class="toc_mobile_items-number">5.</span> <span class="toc_mobile_items-text">Extras</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#Change-Machines’-Username"><span class="toc_mobile_items-number">5.1.</span> <span class="toc_mobile_items-text">Change Machines’ Username</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#Docker-Suspended-Not-in-use"><span class="toc_mobile_items-number">5.2.</span> <span class="toc_mobile_items-text">Docker (Suspended - Not in use)</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#Useful-Commands"><span class="toc_mobile_items-number">5.3.</span> <span class="toc_mobile_items-text">Useful Commands</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#1-General-Commands"><span class="toc_mobile_items-number">5.3.1.</span> <span class="toc_mobile_items-text">1. General Commands</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#2-Resetting-PATH-In-case-if-the-PATH-is-overwritten-by-mistake"><span class="toc_mobile_items-number">5.3.2.</span> <span class="toc_mobile_items-text">2. Resetting $PATH (In case if the $PATH is overwritten by mistake)</span></a></li></ol></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#References"><span class="toc_mobile_items-number">6.</span> <span class="toc_mobile_items-text">References</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#1-Hadoop"><span class="toc_mobile_items-number">6.0.1.</span> <span class="toc_mobile_items-text">1. Hadoop</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#2-Java-JDK"><span class="toc_mobile_items-number">6.0.2.</span> <span class="toc_mobile_items-text">2. Java JDK</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#3-Spark"><span class="toc_mobile_items-number">6.0.3.</span> <span class="toc_mobile_items-text">3. Spark</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#4-Jupyter-Notebook"><span class="toc_mobile_items-number">6.0.4.</span> <span class="toc_mobile_items-text">4. Jupyter Notebook</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#5-HDFS"><span class="toc_mobile_items-number">6.0.5.</span> <span class="toc_mobile_items-text">5. HDFS</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#6-Docker"><span class="toc_mobile_items-number">6.0.6.</span> <span class="toc_mobile_items-text">6. Docker</span></a></li></ol></li></div></div></div><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/js-cookie@2/src/js.cookie.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script src="/js/third-party/fireworks.js"></script><script src="/js/nightshift.js"></script><script id="ribbon" src="/js/third-party/canvas-ribbon.js" size="150" alpha="0.6" zindex="-1" data-click="false"></script><script id="ribbon" src="https://cdn.jsdelivr.net/gh/jerryc127/CDN@latest/js/piao.js"></script><script src="/js/activate-power-mode.js"></script><script>POWERMODE.colorful = true; // make power mode colorful
POWERMODE.shake = true; // turn off shake
document.body.addEventListener('input', POWERMODE);
</script><script src="/js/tw_cn.js"></script><script>translateInitilization()

</script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page@1.2.2/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/lozad/dist/lozad.min.js"></script><script>const observer = lozad(); // lazy loads elements with default selector as '.lozad'
observer.observe();</script></body></html>